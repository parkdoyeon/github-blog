<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Park Doyeon</title>
  
  
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://parkdoyeon.github.io/"/>
  <updated>2019-06-08T11:12:49.743Z</updated>
  <id>https://parkdoyeon.github.io/</id>
  
  <author>
    <name>Park Doyeon</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hexo에 mathjax 적용하기</title>
    <link href="https://parkdoyeon.github.io/web/web-2019-06-07-mathjax/"/>
    <id>https://parkdoyeon.github.io/web/web-2019-06-07-mathjax/</id>
    <published>2019-06-07T08:02:33.000Z</published>
    <updated>2019-06-08T11:12:49.743Z</updated>
    
    <content type="html"><![CDATA[<p>머신러닝 공부를 하다보니 수식을 입력해야하는데, 처음에는 직접 cdn을 호출해서 적용했었다. 꽤 간단하게 되는 것 같아 별도로 수정을 안하다가 어느날 로그(\(logx\))입력시 브라켓({})에서 띄워쓰기를 안해주니 다음과 같이 렌더링 에러가 났다.</p><pre><code class="bash">Template render error: (unknown path) [Line 14, Column 244]  expected variable end    at Object._prettifyError (/Users/doyeon/Dev/blog/node_modules/nunjucks/src/lib.js:36:11)    at Template.render (/Users/doyeon/Dev/blog/node_modules/nunjucks/src/environment.js:542:21)    at Environment.renderString (/Users/doyeon/Dev/blog/node_modules/nunjucks/src/environment.js:380:17)    at Promise.fromCallback.cb (/Users/doyeon/Dev/blog/node_modules/hexo/lib/extend/tag.js:62:48)    at tryCatcher (/Users/doyeon/Dev/blog/node_modules/bluebird/js/release/util.js:16:23)# (후략)</code></pre><p>구글링 하다보니 띄워쓰기가 문제가 되는 경우가 있다고 해서 브라켓에 띄워쓰기를 넣었더니 에러가 사라졌다.<br>이참에 종종 인라인 수식에 적용이 안되는 경우까지 해결해보려고 정석대로 hexo에 mathjax를 적용하도록 하는 글을 찾아봤다.</p><p>정리가 잘 된 글이 있었지만 노드 모듈 스크립트를 직접 수정해야해서 git 저장소를 통해 여러 PC에서 포스트를 작성하는 내 입장에서는 번거로운 구석이 있었다. (node_module이 .gitignore에 있으므로)</p><p>그래서 소스수정이 없는 방식을 찾다가 <a href="https://linkinpark213.com/2018/04/24/mathjax/" rel="external nofollow noopener noreferrer" target="_blank">이 글</a>을 찾았다.<br>블로그 디렉토리에 hexo-math를 다운로드 받아 사용하는 글이다. 그런데 무엇이 잘못됐는지 이상하게</p><ol><li>_config내에 cdn호출 입력해도 페이지에 호출이 안되는데다,</li><li>mathjax를 _config파일 최상위에 정의하는게 deprecate가 되고 있었다.</li><li>게다가 함께 설치되는ㄴ hexo-inject 모듈이 더이상 업데이트가 되지 않는다는 안내가 나왔다.</li></ol><p>알고보니 인라인에 적용이 안되는 문제는</p><pre><code>$ 이렇게 $ 쓰던걸 \\( 이렇게 \\) 바꾸니까 해결이 됐다.</code></pre><p>정리하면,</p><ol><li>header영역에 cdn 호출 스크립트 직접 추가하고<pre><code class="sass">&lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</code></pre></li><li>수식입력하기만 바꾸는걸로.<pre><code>$$  수식 $$ # 단독입력\\( 수식 )\\ # 인라인 입력</code></pre></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;머신러닝 공부를 하다보니 수식을 입력해야하는데, 처음에는 직접 cdn을 호출해서 적용했었다. 꽤 간단하게 되는 것 같아 별도로 수정을 안하다가 어느날 로그(\(logx\))입력시 브라켓({})에서 띄워쓰기를 안해주니 다음과 같이 렌더링 에러가 났
      
    
    </summary>
    
      <category term="Web" scheme="https://parkdoyeon.github.io/web/"/>
    
    
      <category term="web" scheme="https://parkdoyeon.github.io/tags/web/"/>
    
      <category term="hexo" scheme="https://parkdoyeon.github.io/tags/hexo/"/>
    
      <category term="mathjax" scheme="https://parkdoyeon.github.io/tags/mathjax/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning From Scratch - 2. 신경망 학습</title>
    <link href="https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/"/>
    <id>https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/</id>
    <published>2019-06-02T05:20:01.000Z</published>
    <updated>2019-06-08T11:11:42.977Z</updated>
    
    <content type="html"><![CDATA[<h3 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h3><ul><li>‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 <strong>자동</strong>으로 획득하는 것을 뜻한다.</li><li>매개변수 최적값을 학습할 수 있도록 해주는 <strong>지표</strong>는 손실함수이다.<ul><li>왜 정확도가 아닌 손실함수인가?<ul><li>정확도를 지표료 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. (= 소숫점 단위로 표현되는 연속적인 수치값이 아닌 단절된 숫자값으로 표현되기가 쉽다.)</li></ul></li></ul></li><li>손실함수를 최대한 작게 만들어주도록 하는 기법중 하나로, 함수의 기울기를 활용하는 것이 ‘경사법’이다.</li><li>입력부터 출력까지 사람의 개입이 없다는 의미에서, 딥러닝을 종단간 기계학습(end-to-end learning)이라고 한다.</li><li>한 데이터셋에만 지나치게 최적화된 상태를 <strong>오버피팅</strong>이라고 한다.</li></ul><h3 id="1-손실함수"><a href="#1-손실함수" class="headerlink" title="1. 손실함수"></a>1. 손실함수</h3><h4 id="1-1-평균-제곱-오차"><a href="#1-1-평균-제곱-오차" class="headerlink" title="1.1 평균 제곱 오차"></a>1.1 평균 제곱 오차</h4><p>$$ E = { { 1\over2 } \sum_ { k } ( y_k-t_k)^2 } $$</p><ul><li>\(y_k\)는 신경망이 추정한 출력값, \(t_k\)는 실제 정답레이블 값(원-핫 인코딩), k는 차원의 수를 의미한다.</li><li>결과값으로 나타난 손실값의 합들이 높을수록 정답과 멀어지고, 적을수록 정답에 가깝다.</li></ul><h4 id="1-2-교차-엔트로피-오차"><a href="#1-2-교차-엔트로피-오차" class="headerlink" title="1.2 교차 엔트로피 오차"></a>1.2 교차 엔트로피 오차</h4><p>$$  E = - { \sum_ { k } t_k logy_k } $$</p><ul><li>여기서 \(logy\)는 자연로그 \(log_en\)를 취한다.</li><li>\(t_k\)는 원-핫 인코딩 값이므로 실질적으로 \(t_k\)가 1일때의 \(logy_k\)을 계산한 값, 즉 정답 추정값의 자연로그를 계산하는 식이 된다.<ul><li>여기서 정답과 거리가 먼 결과가 발생할수록(x가 1에 가까워질수록) 엔트로피 오차(loss)가 더 크게 발생한다.</li><li>\(log_ex=y\)의 그래프<br><img src="/image/ml/2019-06-02-deep2-1.png" alt="log_ex=y의 그래프"></li><li>가령 신경망 출력이 0.6일때 교차 엔트로피 오차가 \(-log0.6 = 0.51\)이라면, 0.1일때는 \(-log0.1=2.3\)이 된다.jn</li></ul></li></ul><h4 id="1-3-미니-배치-함수"><a href="#1-3-미니-배치-함수" class="headerlink" title="1.3 미니 배치 함수"></a>1.3 미니 배치 함수</h4><p>$$  E = - { 1 \over N } \sum { \sum_ { k } t_k logy_k } $$</p><ul><li>앞서서 구한 쿄차 엔트로피 오차를 모두 구해서 갯수만큼 나누면 평균 교차 엔트로피값을 구할 수 있다. 이렇게 하면 훈련 데이터 개수와 관계없이 통일된 지표를 구할 수 있다.</li><li>전체 데이터가 수천 수십만개가 되면 교차 엔트로피 값을 구하는것은 무리가 있으므로 데이터 일부를 추려서 근사치로 이용할 수 있다.</li><li>추려진 일부 데이터를 <strong>미니배치</strong>라고 한다.</li></ul><h3 id="2-수치미분"><a href="#2-수치미분" class="headerlink" title="2. 수치미분"></a>2. 수치미분</h3><h4 id="2-1-수치미분과-오차"><a href="#2-1-수치미분과-오차" class="headerlink" title="2.1 수치미분과 오차"></a>2.1 수치미분과 오차</h4><ul><li>미분방법에는 수치미분과 해석적미분이 있다.<ol><li>수치미분은 실제 변화량을 수치적으로 계산하는 것으로, 변화값인 h에 최대한 작은 값(보통 \(\lim_{h\to0}\)으로 표현된다.)을 대입하여 계산한다.</li><li>해석적 미분은 수식적으로 미분함수를 만들어 미분값을 찾는 것을 의미한다.</li></ol></li><li>수치미분을 코드로직에 적용할때 h의 최솟값을 대입하다보면 아래와 같은 문제가 발생한다.<br>수치미분을 구하는 파이썬 함수를 예로들면,<pre><code class="python">  def numerical_diff(f, x):      h = 10e-50      return (f(x+h)+f(x)/h)</code></pre>  아래와같이 소숫점 8자리 이하부터 생략이 발생해 최종계산에 오차가 발생한다.<pre><code class="bash">  &gt;&gt;&gt; np.float32(1e-50)  0.0</code></pre>  때문에 \(10^{-4}\)정도의 값을 사용할 것을 권장한다.</li><li>수치미분에서 발생하는 오차는 필연적이기 때문에, 변화량이 +h인 미분과 -h인 미분의 중앙값을 구하기도 한다.</li></ul><h4 id="2-2-편미분"><a href="#2-2-편미분" class="headerlink" title="2.2 편미분"></a>2.2 편미분</h4><ul><li>편미분은 변수가 2개 이상인 경우에 사용한다. 3차원으로 그래프가 그려지므로, 미분값을 구할때는 변수 하나에 초점을 맞추고 다른 변수는 값을 고정한다.</li><li>편미분을 한 기울기값을 마이너스를 붙인 2차원 벡터로 표현하면 각 지점에서 낮아지는 방향을 가리킨다. </li><li>이말인 즉, <strong>기울기가 가리키는 곳은 각 장소의 함수에서 함수의 출력 값을 가장 크게 줄이는 방향</strong>이다.</li></ul><h4 id="2-3-경사법"><a href="#2-3-경사법" class="headerlink" title="2.3 경사법"></a>2.3 경사법</h4><ul><li>경사법은 경사 하강법이라고 한다. 손실함수가 최소가 되는 값을 찾기위해 기울기를 활용하는 방법이다.</li><li>기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지는 보장할 수 없다. 실제로 최솟값이 없는 경우가 대부분이다.</li><li>다만 그 방향으로 가야 줄일 수 있다는 사실은 확실하므로, 기울어진 방향으로 일정 거리만큼 이동해나가면서 줄이는게 경사법이라고 한다.</li><li>최솟값을 찾으면 경사 하강법, 최댓값을 찾으면 경사 상승법이다. 단순히 기울기에 마이너스를 붙이냐 아니냐의 차이이므로 방법과 내용의 실질적인 차이는 없다.</li></ul><h3 id="2-3-1-경사법의-수식"><a href="#2-3-1-경사법의-수식" class="headerlink" title="2.3.1 경사법의 수식"></a>2.3.1 경사법의 수식</h3><p>$$ x_0 = x_0 - \eta { \partial f \over \partial x_0 },  x_1 = x_1 - \eta { \partial f \over \partial x_1 } $$</p><ul><li><p>\( \eta \)(eta)기호는 갱신하는 양을 나타낸다. 보통 0.01이나 0.001 등 특정값으로 정해둔다. 신경망 학습에서는 <strong>학습률</strong>이라고 한다.</p></li><li><p>위의 식은 1회의 갱신이 일어나는 식이며, 만족스러운 값이 나타날때까지 갱신을 반복한다.</p><pre><code class="python">  # f: 최적화함수  # init_x: 초기값  # learning_rate: 학습률  # step_num: 경사법에 따른 반복횟쑤   def gradient_descent (f, init_x, learning_rate=0.01, step_num=100):      x=init_x      for i in range(step_num):          grad = numerical_gradient(f, x)          x -= lr*grad      return x</code></pre></li><li><p>학습률과 같은 매개변수를 하이퍼파라미터라고 한다. 가중치/편향과 같은 신경망 매개변수와는 성질이 다른 매개변수이다.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;개요&quot;&gt;&lt;a href=&quot;#개요&quot; class=&quot;headerlink&quot; title=&quot;개요&quot;&gt;&lt;/a&gt;개요&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 &lt;strong&gt;자동&lt;/strong&gt;으로 획득하는 것을 뜻한
      
    
    </summary>
    
      <category term="ML" scheme="https://parkdoyeon.github.io/ml/"/>
    
    
      <category term="machine-learning" scheme="https://parkdoyeon.github.io/tags/machine-learning/"/>
    
      <category term="deep-learning" scheme="https://parkdoyeon.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>도커/도커 컴포즈 설치하고 서비스 시작하기</title>
    <link href="https://parkdoyeon.github.io/docker/docker-2019-05-30-docker-install/"/>
    <id>https://parkdoyeon.github.io/docker/docker-2019-05-30-docker-install/</id>
    <published>2019-05-30T06:25:27.000Z</published>
    <updated>2019-06-08T02:58:52.616Z</updated>
    
    <content type="html"><![CDATA[<h2 id="도커-설치하기"><a href="#도커-설치하기" class="headerlink" title="도커 설치하기"></a>도커 설치하기</h2><ul><li>[<a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#set-up-the-repository" rel="external nofollow noopener noreferrer" target="_blank">Docker 설치 가이드</a>] 최초 설치시 반드시 저장소 등록(SET UP THE REPOSITORY)부터 할 것!</li><li>설치 후 자동시작이지만 혹시 서비스가 꺼져있다면 배시 통해서 도커 서비스 시작<pre><code class="bash">service docker start</code></pre></li></ul><h2 id="도커-서비스가-시작이-안되면-네트워크-확률이-높다"><a href="#도커-서비스가-시작이-안되면-네트워크-확률이-높다" class="headerlink" title="도커 서비스가 시작이 안되면 ? 네트워크 확률이 높다"></a>도커 서비스가 시작이 안되면 ? 네트워크 확률이 높다</h2><ol><li>로그보기.<pre><code class="bash">journalctl -xe</code></pre></li><li>출력되는 로그 자세히 보면 아래와 같은 내용이 있다.<pre><code class="bash">Error starting daemon: Error initionalizing network controller</code></pre></li><li>이럴땐 직접 ip 지정<pre><code class="bash">root$ ip link add name docker0 type bridgeroot$ ip addr add dev docker0 172.17.0.1/16root$ service docker start</code></pre></li></ol><h2 id="Docker-Compose-설치하기"><a href="#Docker-Compose-설치하기" class="headerlink" title="Docker-Compose 설치하기"></a>Docker-Compose 설치하기</h2><ul><li><a href="https://docs.docker.com/compose/install/#install-compose" rel="external nofollow noopener noreferrer" target="_blank">DockerCompose 설치 가이드</a></li><li>서비스 시작하기 전에 엉뚱한 곳에 실행 권한을 주진 않았나 확인하자.</li><li>apt install docker-compose명령어로 설치하면 구버전(2.2)이 설치된다. 최신버전인 3.2로 설치하기위해선 설치가이드 따르는 것이 좋다.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;도커-설치하기&quot;&gt;&lt;a href=&quot;#도커-설치하기&quot; class=&quot;headerlink&quot; title=&quot;도커 설치하기&quot;&gt;&lt;/a&gt;도커 설치하기&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;[&lt;a href=&quot;https://docs.docker.com/install/li
      
    
    </summary>
    
      <category term="Docker" scheme="https://parkdoyeon.github.io/docker/"/>
    
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="install" scheme="https://parkdoyeon.github.io/tags/install/"/>
    
  </entry>
  
  <entry>
    <title>ElastAlert의 유용한 규칙 종류</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-05-29-elastalert/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-05-29-elastalert/</id>
    <published>2019-05-29T11:07:16.000Z</published>
    <updated>2019-06-08T02:58:52.618Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/Yelp/elastalert" target="_blank" rel="noopener">ElastAlert</a>은 조건에 따라 Elasticsearch에서 발생하는 문서에 대한 알럿을 보내주는 오픈소스이다. 각각의 규칙(Rule) yml파일을 생성하면 지정한 Rule 디렉토리에 있는 설정대로 ES에 쿼리하는 구조로,<br>직접 파일을 생성해서 관리해줄수도 있고, Kibana에 ElastAlert 플러그인을 추가해서 규칙 관리를 할수도 있다. </p><p>규칙은 다양한 타입이 있는데, ELK 로그 스택을 운영하면서 가장 많이 활용했던 Rule타입은 아래와 같다. 전반적인 내용은 <a href="https://elastalert.readthedocs.io/en/latest/ruletypes.html" rel="external nofollow noopener noreferrer" target="_blank">공식문서</a>를 참조하면된다.</p><h2 id="cardinality-특정-필드의-값의-종류를-제한하고싶을때"><a href="#cardinality-특정-필드의-값의-종류를-제한하고싶을때" class="headerlink" title="cardinality: 특정 필드의 값의 종류를 제한하고싶을때"></a>cardinality: 특정 필드의 값의 종류를 제한하고싶을때</h2><pre><code class="yml">name: gender alerttype: cardinalityindex: customer-%Y.%m.%duse_strftime_index: truecardinality_field: &quot;gender&quot; # 제약을 두고싶은 필드# 종류의 갯수(반대로 최소값을 설정하고싶으면 min_cardinality으로 세팅)max_cardinality: 2  alert_subject: &quot;남/녀 외의 또 다른 필드값 발생!&quot;</code></pre><h2 id="metric-aggregation-특정-값의-발생-빈도를-카운팅하고싶을-때"><a href="#metric-aggregation-특정-값의-발생-빈도를-카운팅하고싶을-때" class="headerlink" title="metric_aggregation: 특정 값의 발생 빈도를 카운팅하고싶을 때"></a>metric_aggregation: 특정 값의 발생 빈도를 카운팅하고싶을 때</h2><pre><code class="yml">name: sql datatype: metric_aggregationindex: inserted-sql-data-%Y.%m.%duse_strftime_index: truemetric_agg_key: &quot;pk-field&quot; # 카운팅 하고싶은 대상 필드의 이름metric_agg_type: value_count # value가 되는 값의 count를 한다는 것을 의미, 숫자크기와 같은 다른 방식의 카운팅방법 지정도 가능하다.query_key: &quot;pk-field.keyword&quot; # 대상으로 할 value에 대한 쿼리를 넣어주면 된다 max_threshold: 1 # 내 경우 중복이 발생하면 무조건 알럿이 와야하므로 최대 갯수는 1개.doc_type: docalert_subject: &quot;pk-field에 중복된 값이 있습니다.&quot;</code></pre><h2 id="any-어떤-문서든-발생하면-바로"><a href="#any-어떤-문서든-발생하면-바로" class="headerlink" title="any: 어떤 문서든 발생하면 바로!"></a>any: 어떤 문서든 발생하면 바로!</h2><pre><code class="yml">name: Fatal Errortype: anyindex: fatal-log-%Y.%m.%duse_strftime_index: truefilter:- query:    query_string:      query: &quot;log.level: fatal&quot;alert_subject: &quot;fatal 에러가 발생했습니다.&quot;</code></pre><h2 id="frequency-특정-갯수-이상의-문서가-발생했을때"><a href="#frequency-특정-갯수-이상의-문서가-발생했을때" class="headerlink" title="frequency: 특정 갯수 이상의 문서가 발생했을때"></a>frequency: 특정 갯수 이상의 문서가 발생했을때</h2><pre><code class="yml">name: Web Error Alerttype: frequencyindex: web-log-%Y.%m.%duse_strftime_index: true# 10분간 20번의 에러 로그가 발생하면 알럿num_events: 20timeframe:  minutes: 10filter:- query:    query_string:      query: &quot;fields.level: error&quot;alert_subject: &quot;지속적인 에러가 발생했습니다.&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://github.com/Yelp/elastalert&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ElastAlert&lt;/a&gt;은 조건에 따라 Elasticsearch에서 발생하는 문서에 대한 알럿을 보내주는 오
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elk" scheme="https://parkdoyeon.github.io/tags/elk/"/>
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="elastalert" scheme="https://parkdoyeon.github.io/tags/elastalert/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins에 Python 환경세팅하고 Allure Report 연동하기</title>
    <link href="https://parkdoyeon.github.io/python/python-2019-05-28-jekins-to-pytest/"/>
    <id>https://parkdoyeon.github.io/python/python-2019-05-28-jekins-to-pytest/</id>
    <published>2019-05-28T06:17:02.000Z</published>
    <updated>2019-06-08T02:58:52.619Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Jekins에-파이썬-세팅하기"><a href="#Jekins에-파이썬-세팅하기" class="headerlink" title="Jekins에 파이썬 세팅하기"></a>Jekins에 파이썬 세팅하기</h1><ol><li>System Configuration &gt; Global Properties &gt; Environment Variables 체크<ul><li>이름: <code>PYTHON_PATH</code></li><li>값: <code>C:\Python\Python36;C:\Python\Python36\Scripts;</code> (젠킨스가 돌아가는 호스트 환경변수에 세팅된 파이썬 경로 입력)</li></ul></li><li>프로젝트 생성 &gt; 구성 &gt; General 탭 &gt; Build &gt; Add build step<ul><li>윈도우라면 Execute Windows Batch Command 선택하고 아래의 스크립트 추가</li><li>패키지 변경감지를 위해 파이썬 가상환경을 세팅하고 pip install 세팅<pre><code class="bash">SET PATH=%PATH%,%PYTHON_PATH%virtualenv venvcall venv/Scripts/activate.batpip install -r requirements.txtpy.test --alluredir=./allure-results # pytest의 allure report 결과 생성을 위한 디렉토리 설정deactivate</code></pre></li></ul></li></ol><h1 id="Jenkins에-Allure-Report-세팅"><a href="#Jenkins에-Allure-Report-세팅" class="headerlink" title="Jenkins에 Allure Report 세팅"></a>Jenkins에 Allure Report 세팅</h1><ol><li>플러그인 관리 &gt; 설치가능탭 &gt; Allure Jenkins Plugin 설치</li><li>프로젝트 생성 &gt; 구성 &gt; General 탭 &gt; Build &gt; 빌드 후 조치 &gt; 빌드 후 조치 추가<ul><li>Allure Report 선택 후, 위의 py.test에 파라미터로 넘긴 allure-results path를 넣어준다.<br><img src="/image/python/2019-05-28-jekins-to-pytest-1.PNG" alt="jenkins"></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Jekins에-파이썬-세팅하기&quot;&gt;&lt;a href=&quot;#Jekins에-파이썬-세팅하기&quot; class=&quot;headerlink&quot; title=&quot;Jekins에 파이썬 세팅하기&quot;&gt;&lt;/a&gt;Jekins에 파이썬 세팅하기&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;System C
      
    
    </summary>
    
      <category term="Python" scheme="https://parkdoyeon.github.io/python/"/>
    
    
      <category term="python" scheme="https://parkdoyeon.github.io/tags/python/"/>
    
      <category term="jenkins" scheme="https://parkdoyeon.github.io/tags/jenkins/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning From Scratch - 1. 퍼셉트론과 신경망</title>
    <link href="https://parkdoyeon.github.io/ml/ml-2019-05-27-deep/"/>
    <id>https://parkdoyeon.github.io/ml/ml-2019-05-27-deep/</id>
    <published>2019-05-27T10:38:00.000Z</published>
    <updated>2019-06-08T02:58:52.619Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-퍼셉트론"><a href="#1-퍼셉트론" class="headerlink" title="1. 퍼셉트론"></a>1. 퍼셉트론</h2><ul><li>뉴런에서 보내온 신호 총합이 정해진 한계(임계값)를 넘어서면 1, 아니면 0을 출력하는게 기본 원리.</li><li>신호는 가중치값 \(w\)와 곱한다.<ul><li>전류에서 말하는 저항을 생각하면 된다.</li><li>가중치가 높으면 신호가 크고, 가중치가 낮으면 신호가 낮다.</li></ul></li><li>활성화를 조정하는 상수 편향값 \(b\)를 더한다.</li><li>한계: AND, NAND(Not And: And의 반대 진리표), OR의 연산 구현이 가능하지만, XOR 게이트는 구현할 수 없다.</li></ul><h2 id="2-다층-퍼셉트론"><a href="#2-다층-퍼셉트론" class="headerlink" title="2. 다층 퍼셉트론"></a>2. 다층 퍼셉트론</h2><ul><li>선형구조인 퍼셉트론의 대안으로, 다층적으로 구현하는 퍼셉트론을 말한다.</li><li>다층 퍼셉트론의 NAND 연산만으로 컴퓨터를 구현할 수 있다.</li></ul><h2 id="3-신경망"><a href="#3-신경망" class="headerlink" title="3. 신경망"></a>3. 신경망</h2><ul><li>입력층, 은닉층, 출력층으로 구성되어있다.</li><li>두개의 신호 \(w_1\), \(w_2\)와 편향값 b가 있다고 가정할때, 다음과 같이 표현할 수 있다.<br>$$ y= h(b+w_1x_1+w_2x_2) $$</li><li>여기서 출력값 y를 도출하는 h(a)로 표현되는 함수는 활성화 함수라고 한다.</li></ul><h4 id="3-1-활성화-함수"><a href="#3-1-활성화-함수" class="headerlink" title="3.1 활성화 함수"></a>3.1 활성화 함수</h4><ul><li>활성화 함수는 신호의 총합을 출력의 신호로 변환하는 함수를 말한다.</li><li>신경망은 활성화 함수를 통해 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다.</li><li>책에서는 활성화 함수로 세 가지를 소개한다.<ol><li>계단함수<ul><li>입력이 0을 넘으면 1을, 그 외에는 0을 출력하는 함수이다.</li></ul></li><li>시그모이드 함수<ul><li>시그모이드 함수는 아래의 공식을 나타내며, e는 자연상수이다.<br>$$ h(x)= {1 \over 1+exp(-x)}$$<br>$$  exp(-x) = e^{-x}, e=2.7182… $$</li></ul></li><li>ReLU 함수<ul><li>입력이 0을 넘으면 그 입력을 그대로 출력하고, 0이하면 0을 출력하는 함수이다.</li></ul></li></ol></li><li>세 함수는 공통적으로 비선형 함수이고, 신경망에서는 활성화 함수로 비선형 함수를 사용해야한다<ul><li>선형함수를 이용하면 미분값이 값이 상수가 되며, 변화량이 상수면 신경망 층을 깊게하는 의미가 없어지기 때문이다.</li></ul></li></ul><h4 id="3-2-출력층-설계하기"><a href="#3-2-출력층-설계하기" class="headerlink" title="3.2 출력층 설계하기"></a>3.2 출력층 설계하기</h4><ul><li>기계학습은 분석(classification, 입력데이터를 구분), 회귀(regression, 입력데이터에서 연속적인 수치 예측)따라 활성화 함수를 달리쓴다.</li><li>두가지를 소개한다.<ol><li>항등함수<ul><li>회귀에서 주로 사용한다. 입력을 그대로 출력함.</li></ul></li><li>소프트맥스<ul><li>분류에서 주로 사용한다.</li><li>분자는 입력신호의 지수함수, 분모는 n개의 모든 입력신호의 지수함수의 합으로 구성된다<br> $$  y_k = {exp(a_k) \over \sum_ {i=0}^n exp(a_i)} $$<ul><li>분모의 값을 보면 모든 출력층의 뉴런이 모든 신호로부터 영향을 받는 것을 알 수 있다.</li><li>소프트 맥스 함수는 코드 구현시 지수값으로 인한 오버플로 문제가 있다. 이를 개선하기 위해 입력신호중 최대값을 뺀다.</li><li>아래의 식을 보면 어떤값을 더하거나 뺴도 결과값은 동일하다는 것을 보여준다.<br>$$  y_k = {exp(a_k) \over \sum_ {i=0}^n exp(a_i)} = {Cexp(a_k) \over C\sum_ {i=0}^n exp(a_i)}  $$<br>\(exp(n)\)는 지수함수이므로 C를 지수식에 밑이 e인 자연로그($log_e$)으로 취하면 덧셈식에 넣을 수 있다.<br>$$  = {exp(a_k+logC) \over \sum_ {i=0}^n exp(a_i+logC)} = {exp(a_k+C’) \over \sum_ {i=0}^n exp(a_i+C’)}$$</li></ul></li><li>소프트 맥스 함수의 출력은 0부터 1사이의 실수이며, 그렇기 때문에 출력을 확률로 해석할 수 있다.</li><li>\(y=exp(x)\)형식의 단조 증가함수이므로 원소간의 대소관계가 바뀌지는 않는다.</li><li>그렇기 떄문에 지수함수 계산에 드는 자원 낭비를 줄이기 위해 현업에서는 출력층의 소프트맥스 함수를 생략하기도 한다.</li></ul></li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-퍼셉트론&quot;&gt;&lt;a href=&quot;#1-퍼셉트론&quot; class=&quot;headerlink&quot; title=&quot;1. 퍼셉트론&quot;&gt;&lt;/a&gt;1. 퍼셉트론&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;뉴런에서 보내온 신호 총합이 정해진 한계(임계값)를 넘어서면 1, 아니면 0을 출력
      
    
    </summary>
    
      <category term="ML" scheme="https://parkdoyeon.github.io/ml/"/>
    
    
      <category term="machine-learning" scheme="https://parkdoyeon.github.io/tags/machine-learning/"/>
    
      <category term="deep-learning" scheme="https://parkdoyeon.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>ssms 사용할때 자주쓰는 명령어 정리</title>
    <link href="https://parkdoyeon.github.io/sql/sql-2019-05-27-ssms/"/>
    <id>https://parkdoyeon.github.io/sql/sql-2019-05-27-ssms/</id>
    <published>2019-05-27T08:36:00.000Z</published>
    <updated>2019-06-08T02:58:52.620Z</updated>
    
    <content type="html"><![CDATA[<p>SP 내용 보기</p><pre><code class="sql">sp_helptext &#39;[sp 이름]&#39;</code></pre><p>특정 구문이 포함되어있는 SP 찾기 (특정 테이블이나 컬럼을 사용하는 SP를 찾을때 유용하다)</p><pre><code class="sql">select * from sys.procedures p join sys.syscomments s on p.object_id = s.id where text like &#39;%[문자열]%&#39;;</code></pre><p>프로파일러 잡을때 DB ID 확인이 필요한경우</p><pre><code class="sql">select db_id(&#39;[db 이름]&#39;)</code></pre><p>도구 &gt; 옵션 &gt; 키보드 &gt; 쿼리 바로가기에서 아래처럼 키보드 단축키로 설정하고 사용하면 좋다.<br><img src="/image/sql/2019-05-27-ssms.png" alt="옵션"></p><ul><li>sp_lock : sp들의 점유상태를 보고싶을 때</li><li>sp_who : DB 로그인 정보와 호스트 확인</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SP 내용 보기&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;sp_helptext &amp;#39;[sp 이름]&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;특정 구문이 포함되어있는 SP 찾기 (특정 테이블이나 컬럼을 사용하는 SP를 찾을때 유용하다)&lt;/p
      
    
    </summary>
    
      <category term="SQL" scheme="https://parkdoyeon.github.io/sql/"/>
    
    
      <category term="mssql" scheme="https://parkdoyeon.github.io/tags/mssql/"/>
    
      <category term="insert" scheme="https://parkdoyeon.github.io/tags/insert/"/>
    
  </entry>
  
  <entry>
    <title>Hyper-V - 네트워크 환경세팅하기</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-04-29-hyperv/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-04-29-hyperv/</id>
    <published>2019-04-29T07:47:00.000Z</published>
    <updated>2019-06-08T02:58:52.615Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>네트워크를 설정할 가상컴퓨터를 누르고 오른쪽 작업란에 가상 스위치 관리자버튼 클릭</p></li><li><p>외부/내부/개인 중에 ‘내부’로 두가지 생성</p></li></ol><ul><li>외부: 호스트PC와 동위선상에서 네트워킹</li><li>내부: 호스트PC 네트워크를 타고 분기</li><li>외부/내부 두가지 방법으로 설정 다 가능하다. 다만 사내망 정책에 따라 외부로 설정하면 간혹 안되는 경우가 있으니 안전하게 내부로 설정하자</li></ul><ol start="3"><li><p>여러개의 Hyper V 가상 PC가 있다면 ‘내부용 스위치’로 외부통신을 위한 공유네트워크 카드 하나, 호스트통신 전용으로 하나 해서 스위치 두개를 만든다.</p><pre><code class="bash">sudo vi /etc/network/interfaces</code></pre><p> <img src="/image/dev-env/2019-04-29-hyperv1.jpeg" alt="설정 화면"></p></li><li><p>제어판&gt;네트워크 및 인터넷&gt;네트워크 연결에 들어가서 이더넷(호스트PC의 네트워크)의 속성&gt;공유 클릭</p></li><li><p>다른네트워크 사용자가 연결할수 있도록 허용체크, 홈네트워킹으로 “공유네트워크”를 설정해준다.</p><p> <img src="/image/dev-env/2019-04-29-hyperv2.png" alt="설정 화면2"></p></li><li><p>가상머신의 터미널에서 ifconfig를 입력하면 eith0(공유네트워크)는 DHCP를 통해 자동으로 IP가 생성되는 한편, eith1은 아직 IP를 할당받지 못한 상태</p><p> <img src="/image/dev-env/2019-04-29-hyperv3.jpeg" alt="IP Table"></p></li><li><p>아래의 명령어로 네트워크 설정 파일에 eth1의 고정ip를 다음과 같이 입력해준다.</p><pre><code class="bash">sudo vi /etc/network/interfaces</code></pre><p><img src="/image/dev-env/2019-04-29-hyperv4.png" alt="IP Table2"></p></li><li><p>네트워크 재시작 하면 끝~</p><pre><code class="bash">sudo systemctl restart networking.service</code></pre></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;네트워크를 설정할 가상컴퓨터를 누르고 오른쪽 작업란에 가상 스위치 관리자버튼 클릭&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;외부/내부/개인 중에 ‘내부’로 두가지 생성&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;외부: 호스트PC와 동위선상
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="network" scheme="https://parkdoyeon.github.io/tags/network/"/>
    
      <category term="Hyper-V" scheme="https://parkdoyeon.github.io/tags/hyper-v/"/>
    
  </entry>
  
  <entry>
    <title>Python - 독립실행환경 virtualenv 만들기</title>
    <link href="https://parkdoyeon.github.io/python/python-2019-04-18-python-venv/"/>
    <id>https://parkdoyeon.github.io/python/python-2019-04-18-python-venv/</id>
    <published>2019-04-18T09:32:00.000Z</published>
    <updated>2019-06-08T02:58:52.619Z</updated>
    
    <content type="html"><![CDATA[<p>virtaulenv를 통해 활상화된 가상환경 아래에서 개발하면,<br>파이썬 실행환경을 독립적으로 관리할 수 있는 것은 물론이고, 모듈관리를 체계적으로 할 수 있다.</p><p>pip 인스톨을 통해 virtualenv를 설치하고,<br>해당 프로젝트 경로에서 virtualenv 명령어를 통해 가상환경 이름을 명명하면<br>해당 디렉토리에 가상환경 디렉토리가 생성된다.</p><pre><code class="bash">pip3 install virtualenvcd [프로젝트 폴더]virtualenv venv</code></pre><h1 id="가상환경-활성화하기"><a href="#가상환경-활성화하기" class="headerlink" title="가상환경 활성화하기"></a>가상환경 활성화하기</h1><p>윈도우와 리눅스 활성화 방식이 조금씩 다르다. 위에가 윈도우고 아래가 리눅스 실행 명령어이다. </p><pre><code class="bash">venv/scripts/activatesource venv/bin/activate</code></pre><h1 id="비활성화-하기"><a href="#비활성화-하기" class="headerlink" title="비활성화 하기"></a>비활성화 하기</h1><pre><code class="bash">deactivate</code></pre><h1 id="패키지-정리-파일-만들기"><a href="#패키지-정리-파일-만들기" class="headerlink" title="패키지 정리 파일 만들기"></a>패키지 정리 파일 만들기</h1><pre><code class="bash">pip freeze &gt; requirement.txt</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;virtaulenv를 통해 활상화된 가상환경 아래에서 개발하면,&lt;br&gt;파이썬 실행환경을 독립적으로 관리할 수 있는 것은 물론이고, 모듈관리를 체계적으로 할 수 있다.&lt;/p&gt;
&lt;p&gt;pip 인스톨을 통해 virtualenv를 설치하고,&lt;br&gt;해당 프
      
    
    </summary>
    
      <category term="Python" scheme="https://parkdoyeon.github.io/python/"/>
    
    
      <category term="python" scheme="https://parkdoyeon.github.io/tags/python/"/>
    
      <category term="venv" scheme="https://parkdoyeon.github.io/tags/venv/"/>
    
      <category term="pip" scheme="https://parkdoyeon.github.io/tags/pip/"/>
    
  </entry>
  
  <entry>
    <title>Git - 실수로 용량이 큰 파일을 커밋했을 때</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-04-07-git-large-file/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-04-07-git-large-file/</id>
    <published>2019-04-07T10:14:00.000Z</published>
    <updated>2019-06-08T02:58:52.615Z</updated>
    
    <content type="html"><![CDATA[<p>회사에서 gitlab을 쓰면서 쾌적한 git life를 즐기다가 github에서는 100MB이상의 파일이 푸시가 안된다는 것을 알았다.<br>R 스터디 할때 써놓은 코드를 기록하려고 데이터와 함께 커밋을 해버렸는데, 커밋때 경고가 한번 떴(던거같은데)다가 푸시할때도 아래와 같은 에러를 뱉으며 push fail이 일어났다</p><pre><code class="bash">remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.</code></pre><p>–force 명령어에도 푸시가 안돼서 찾아보니, filter-branch를 통해 커밋 히스토리에서 삭제해야한다고.</p><pre><code class="bash">git filter-branch --tree-filter &#39;rm -f path/to/bigRdata/biggy.sav&#39; HEADgit push origin master --force</code></pre><p>필터 브랜치 명령어에서 삭제할 데이터의 path는 git bash에서 접근한 경로기준으로 (보통은 git의 루트디렉토리) 입력하면 된다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;회사에서 gitlab을 쓰면서 쾌적한 git life를 즐기다가 github에서는 100MB이상의 파일이 푸시가 안된다는 것을 알았다.&lt;br&gt;R 스터디 할때 써놓은 코드를 기록하려고 데이터와 함께 커밋을 해버렸는데, 커밋때 경고가 한번 떴(던거같
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="git" scheme="https://parkdoyeon.github.io/tags/git/"/>
    
      <category term="filter-branch" scheme="https://parkdoyeon.github.io/tags/filter-branch/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch - 도커를 이용해 인덱스 주기적으로 삭제하기</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-04-02-es-curator/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-04-02-es-curator/</id>
    <published>2019-04-02T08:35:00.000Z</published>
    <updated>2019-06-08T02:58:52.618Z</updated>
    
    <content type="html"><![CDATA[<p>로그를 끊임없이 ES에 저장하다보면 디스크 용량이 부족한 문제가 발생한다.<br>수동으로 인덱스를 삭제하다보면 단순히 번거로울 뿐만이 아니라 삭제하지 않으려고 했던 인덱스도 삭제될 수 있기 때문에, 삭제 자동화는 ES 운영에 반드시 필요하다.<br>curator는 elasticsearch의 인덱스를 관리를 위한 어플리케이션으로, ES와 격리된 환경에서 http 통신으로 동작이 가능하다.</p><p>여기에는 인덱스 삭제만 나와있지만, 샤드의 삭제나 엘라스틱서치의 스냅샷 삭제, 샤드 라우팅 변경도 가능하다.<br>나의 경우 curator를 세팅할 서버는 폐쇄된 환경이었기 때문에,<br>로컬에서 curator 공식사이트의 dockerfile을 받아 이미지를 빌드한 다음,<br>이미지를 파일로 압축해 서버에 세팅하고 cronjob을 통해 매일 인덱스 삭제작업을 진행하도록 했다.</p><h4 id="docker-image-빌드"><a href="#docker-image-빌드" class="headerlink" title="docker image 빌드"></a>docker image 빌드</h4><p>github에 올라와있는 dockerfile을 다운받아 빌드한다 <a href="https://github.com/elastic/curator" target="_blank" rel="noopener">https://github.com/elastic/curator</a></p><pre><code class="bash">docker build .</code></pre><h4 id="큐레이터-기본-설정파일-생성하기-curator-yml"><a href="#큐레이터-기본-설정파일-생성하기-curator-yml" class="headerlink" title="큐레이터 기본 설정파일 생성하기: curator.yml"></a>큐레이터 기본 설정파일 생성하기: curator.yml</h4><pre><code class="yml">client:  hosts:   - elasticsearch  port: 9200  url_prefix:  use_ssl: False  certificate:  client_cert:  client_key:  ssl_no_validate: False  http_auth:  timeout: 30  master_only: Falselogging:  loglevel: INFO  logfile: /volume/curator.log #로그 디렉토리 설정, 어플리케이션 수행   logformat: default  blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;]</code></pre><h4 id="인덱스-삭제-규칙파일-생성하기-delete-indices-yml"><a href="#인덱스-삭제-규칙파일-생성하기-delete-indices-yml" class="headerlink" title="인덱스 삭제 규칙파일 생성하기: delete-indices.yml"></a>인덱스 삭제 규칙파일 생성하기: delete-indices.yml</h4><pre><code class="yml">actions:  1:    action: delete_indices    options:      ignore_empty_list: True      disable_action: False    filters:     - filtertype: pattern       kind: prefix       value: kr-*-     - filtertype: age       source: name       direction: older       timestring: &#39;%Y.%m.%d&#39;       unit: days       unit_count: 8 #생성한지 8일이 된 데이터는 삭제한다</code></pre><h4 id="도커-컴포즈-설정"><a href="#도커-컴포즈-설정" class="headerlink" title="도커 컴포즈 설정"></a>도커 컴포즈 설정</h4><p>빌드된 이미지의 entrypoint는 아무 옵션 없이 단순히 어플리케이션을 실행하는 ‘curator/curator’이다.<br>때문에 설정파일이나 규칙들을 정의해주고싶다면 아래와 같이 entrypoint override를 해야한다.<br>또한, 어떤 인덱스가 삭제될지 확인하고싶다면 dry run 옵션을 통해 위의 curator.yml에 지정한 log파일에서 리스트확인이 가능하다.<br>최초 실행시 반드시 dry run을 통해 curator.log에 삭제 대상이 되는 인덱스들을 확인하자.</p><pre><code class="yml">version: &#39;3.3&#39;  services:    curator:      image: curator:5.6      container_name: curator      user: $USER      volumes:        - /data/volume/curator:/volume  # 테스트시 주석 해제 후 실행  #    entrypoint: [&quot;curator/curator&quot;, &quot;--config&quot;, &quot;/volume/config/curator.yml&quot;, &quot;--dry-run&quot;, &quot;/volume/config/delete-indices.yml&quot;]      entrypoint: [&quot;curator/curator&quot;, &quot;--config&quot;, &quot;/volume/config/curator.yml&quot;, &quot;/volume/config/delete-indices.yml&quot;]      network_mode: esmaster #엘라스틱 서치가 있는 네트워크와 맞춰주기</code></pre><h4 id="큐레이터로-도커컴포즈-실행하기"><a href="#큐레이터로-도커컴포즈-실행하기" class="headerlink" title="큐레이터로 도커컴포즈 실행하기"></a>큐레이터로 도커컴포즈 실행하기</h4><p>도커 컨테이너는 규칙 실행후 exit code 0을 반환하며 종료된다.<br>정기적으로 실행되도록 설정하려면 리눅스 cronjob 등록을 해줘야한다.</p><ol><li>도커 컴포즈 실행 스크립트 만들기<pre><code class="bash">#!/bin/bashcd /path/to/docker-composedocker-compose up</code></pre></li></ol><pre><code>2. 크론탭 에디터 열기``` bashcrontab -e</code></pre><ol start="3"><li>규칙 추가<br>매일 17시에 실행되고, cronjob 작업 수행 이력이 crontab.log에 남는다.<pre><code class="bash">0 17 * * * /data/volume/curator-run.sh &gt; /data/crontab.log 2&gt;&amp;1</code></pre></li></ol><p>완료후 반영은 wq를 통해 하면 된다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;로그를 끊임없이 ES에 저장하다보면 디스크 용량이 부족한 문제가 발생한다.&lt;br&gt;수동으로 인덱스를 삭제하다보면 단순히 번거로울 뿐만이 아니라 삭제하지 않으려고 했던 인덱스도 삭제될 수 있기 때문에, 삭제 자동화는 ES 운영에 반드시 필요하다.&lt;b
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="curator" scheme="https://parkdoyeon.github.io/tags/curator/"/>
    
      <category term="index" scheme="https://parkdoyeon.github.io/tags/index/"/>
    
  </entry>
  
  <entry>
    <title>docker - 이미지/컨테이너 파일로 저장하고 불러오기</title>
    <link href="https://parkdoyeon.github.io/docker/docker-2019-03-29-docker-image/"/>
    <id>https://parkdoyeon.github.io/docker/docker-2019-03-29-docker-image/</id>
    <published>2019-03-29T09:37:00.000Z</published>
    <updated>2019-06-08T02:58:52.616Z</updated>
    
    <content type="html"><![CDATA[<p>도커의 장점을 폐쇄된 네트워크 환경에서 활용하기란 쉽지가 않다.<br>그나마 도커를 사용하니까 폐쇄된 리눅스 환경에서 이만큼의 편의를 가질수 있기도 하고.<br>암튼 매번 업데이트마다 자꾸 여러명의 결재를 거쳐야하는 네트워크인가를 통해 서버를 열기가 껄그러워서, 이미지를 파일로 만들어서 사용하게되었다. 용량때문에 ftp서버 통해서 옮기는데 시간이 조금 걸리지만 그런대로 쓸만하다. 퇴근시간쯤에 이미지를 날려서 처음 이 명령어를 써봤는데, 덕분에 일찍 집에갈 수 있었다.</p><h1 id="이미지-저장하기"><a href="#이미지-저장하기" class="headerlink" title="이미지 저장하기"></a>이미지 저장하기</h1><pre><code class="bash">docker save [option] [image:tag] -o [저장할파일명.tar]</code></pre><h1 id="이미지-불러오기"><a href="#이미지-불러오기" class="headerlink" title="이미지 불러오기"></a>이미지 불러오기</h1><pre><code class="bash">docker load &lt; [tar파일 이름]</code></pre><h1 id="컨테이너-저장하기"><a href="#컨테이너-저장하기" class="headerlink" title="컨테이너 저장하기"></a>컨테이너 저장하기</h1><p>이미지 말고도 컨테이너도 저장하고 불러올 수 있다.</p><pre><code class="bash">docker export [container name] &gt; [저장할파일명.tar]</code></pre><h1 id="컨테이너-불러오기"><a href="#컨테이너-불러오기" class="headerlink" title="컨테이너 불러오기"></a>컨테이너 불러오기</h1><pre><code class="bash">docker import [tar파일 이름]</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;도커의 장점을 폐쇄된 네트워크 환경에서 활용하기란 쉽지가 않다.&lt;br&gt;그나마 도커를 사용하니까 폐쇄된 리눅스 환경에서 이만큼의 편의를 가질수 있기도 하고.&lt;br&gt;암튼 매번 업데이트마다 자꾸 여러명의 결재를 거쳐야하는 네트워크인가를 통해 서버를 열
      
    
    </summary>
    
      <category term="Docker" scheme="https://parkdoyeon.github.io/docker/"/>
    
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="image" scheme="https://parkdoyeon.github.io/tags/image/"/>
    
      <category term="container" scheme="https://parkdoyeon.github.io/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>docker-compose up에서 네트워크 생성이 되지 않을 때</title>
    <link href="https://parkdoyeon.github.io/docker/docker-2019-03-29-compose-network/"/>
    <id>https://parkdoyeon.github.io/docker/docker-2019-03-29-compose-network/</id>
    <published>2019-03-29T09:24:00.000Z</published>
    <updated>2019-06-08T02:58:52.616Z</updated>
    
    <content type="html"><![CDATA[<h1 id="발단"><a href="#발단" class="headerlink" title="발단"></a>발단</h1><p>어떤 환경에서 발생하는지는 정확히 알 수 없지만, 회사의 서버에 도커를 설치하면 기본 ip 대역 생성이 되지않아 아래의 메세지와 함께 도커 실행이 되지 않았다.</p><pre><code class="bash">Error starting daemon: Error initionalizing network controller</code></pre><p>그래서 아래의 명령어로 직접 bridge ip를 추가해줬었다.</p><pre><code class="bash">root$ ip link add name docker0 type bridgeroot$ ip addr add dev docker0 172.17.0.1/16root$ service docker start</code></pre><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>default 네트워크로 bridge를 사용하는 환경에서 컨테이너를 실행해서 잘 사용해오다가,<br>근래에 서버 점검할때마다 컨테이너가 한꺼번에 종료되는 일이 왕왕 발생해서 docker-compose로 정리를 했다.<br>알파에서 테스트를 마치고 라이브 서버에서 docker-compose up 명령을 실행하니,<br>다음과 같은 에러가 발생하면서 어떤 컨테이너도 실행되지 않았다.</p><pre><code class="bash">ERROR: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network”</code></pre><p>‘docker network prune’으로 사용하지 않는 네트워크를 정리를 하면 해결된단 얘기가 있었으나 이 상황은 그렇지않았다.<br>검색해보니 보통은 컨테이너에 너무 많은 ip가 할당되면 이런 문제가 발생한다고 하는데,<br>내게는 이런 문제가 해당되지 않으니까 사용하지 않는 ip를 정리한다고 문제가 해결될것이 아니었다.</p><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><p>그래서 생각하기를, 이 서버는 도커 네트워크 환경을 조성하려면 IP설정을 내가 직접 해줬어야 했으니까,<br>도커컴포즈도 대역 할당을 직접 해줘야하나? 싶어서 네트워크를 생성했다.</p><pre><code class="bash">docker network create --driver=bridge \--subnet=172.72.0.0/16 \--ip-range=172.72.0.0/24 \--gateway=172.72.0.1 \esmaster</code></pre><p>그리고 docker-compose파일에도 각 서비스별로 network_mode: esmaster를 추가해줬더니, 서비스가 잘 올라왔다!</p><p>도커는 아.. 이젠 정말 네트워크 공부를 제대로 해야하나…싶게 만들다가도<br>약간의 직감으로 생각보다 빨리 문제가 해결되는 경우가 있어서 당혹스럽다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;발단&quot;&gt;&lt;a href=&quot;#발단&quot; class=&quot;headerlink&quot; title=&quot;발단&quot;&gt;&lt;/a&gt;발단&lt;/h1&gt;&lt;p&gt;어떤 환경에서 발생하는지는 정확히 알 수 없지만, 회사의 서버에 도커를 설치하면 기본 ip 대역 생성이 되지않아 아래의 메세지
      
    
    </summary>
    
      <category term="Docker" scheme="https://parkdoyeon.github.io/docker/"/>
    
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="docker-compose" scheme="https://parkdoyeon.github.io/tags/docker-compose/"/>
    
  </entry>
  
  <entry>
    <title>Linux - 리눅스 용량, 메모리 정보 확인하기</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-03-26-linux-disk/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-03-26-linux-disk/</id>
    <published>2019-03-26T08:03:00.000Z</published>
    <updated>2019-06-08T02:58:52.615Z</updated>
    
    <content type="html"><![CDATA[<p>리눅스 환경에서 도커로 ELK 스택 서비스를 운영 사용하다보면 로그관리때문에 메모리나 디스크정보 확인을 할 일이 많은데,<br>자주 사용하게 되는 기능들 위주로 정리해보았다.</p><h1 id="메모리"><a href="#메모리" class="headerlink" title="메모리"></a>메모리</h1><ul><li>전체 메모리 정보 확인하기<pre><code class="bash">cat /proc/meminfo | grep MemTotal</code></pre></li><li>사용중인 메모리 확인하기<pre><code class="bash">free</code></pre></li></ul><h1 id="CPU-확인하기"><a href="#CPU-확인하기" class="headerlink" title="CPU 확인하기"></a>CPU 확인하기</h1><pre><code class="bash">cat /proc/cpuinfo | more</code></pre><h1 id="디스크"><a href="#디스크" class="headerlink" title="디스크"></a>디스크</h1><ul><li>전체 디스크, 파티션 용량 확인하기<pre><code class="bash">df -h</code></pre></li><li>디렉토리 기준 용량 확인하기<pre><code class="bash">du -hsx * | sort -rh | head -10</code></pre></li></ul><ul><li>: 경로위치, 생략시 현재 폴더<br>du -h : 용량을 읽기좋은 포멧으로 정리 ex)1K, 200M, 3G ..<br>du -s : 요약<br>du -x : 디렉토리 하위 스킵<br>sort -r : 비교 결과 역순<br>sort -h : 읽기좋은 포멧 형식으로 비교<br>head -10 : 상위 10개까지 보여주기</li></ul><p>참고 페이지<br><a href="https://www.cyberciti.biz/faq/how-do-i-find-the-largest-filesdirectories-on-a-linuxunixbsd-filesystem/" rel="external nofollow noopener noreferrer" target="_blank">https://www.cyberciti.biz/faq/how-do-i-find-the-largest-filesdirectories-on-a-linuxunixbsd-filesystem/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;리눅스 환경에서 도커로 ELK 스택 서비스를 운영 사용하다보면 로그관리때문에 메모리나 디스크정보 확인을 할 일이 많은데,&lt;br&gt;자주 사용하게 되는 기능들 위주로 정리해보았다.&lt;/p&gt;
&lt;h1 id=&quot;메모리&quot;&gt;&lt;a href=&quot;#메모리&quot; class=&quot;
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="linux" scheme="https://parkdoyeon.github.io/tags/linux/"/>
    
      <category term="disk" scheme="https://parkdoyeon.github.io/tags/disk/"/>
    
  </entry>
  
  <entry>
    <title>SVM - 2. svm 사이의 최대 거리값 찾기</title>
    <link href="https://parkdoyeon.github.io/ml/ml-2019-03-19-svm2/"/>
    <id>https://parkdoyeon.github.io/ml/ml-2019-03-19-svm2/</id>
    <published>2019-03-19T08:38:00.000Z</published>
    <updated>2019-06-08T02:58:52.619Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image/ml/2019-03-19-svm2-1.jpeg" alt="그래프"></p><p>다시 그래프로 돌아오자.<br>svm의 가장 기본적인 목표는 경계(decision boundary)에 가장 가까운 서로 다른 클래스 두 점의 ‘거리 최대값’을 찾는 것이다.<br>위 그래프에서 초록색 선은 x-클래스 벡터, 하늘색 선은 x+클래스 벡터이다.<br>뺄셈으로 두 벡터의 거리를 찾고, 벡터값을 스칼라로 바꾸기 위해 w벡터의 단위벡터값을 내적해준다. </p><p><img src="/image/ml/2019-03-19-svm2-2.png" alt="수식"></p><p>왜 하필 w벡터일까? SVM 조건식을 통해 도출한 X와 W의 내적값을 1과 b에 대한 상수식으로 치환하면,<br>아래와 같이 아주 깔끔한 식이 도출된다.</p><p><img src="/image/ml/2019-03-19-svm2-3.png" alt="수식"></p><p>||w||가 분모에 있다는 것은 다시말해 최대값을 찾기위해서는 가장 작은 w를 찾아야한다는 얘기가 된다.<br>수학적 편의에 차원에서 w의 최솟값을 찾기 위해 아래와같이 식을 변형한다.</p><p><img src="/image/ml/2019-03-19-svm2-4.png" alt="수식"></p><p>‘왜 이렇게 변형해야 하는가’는 또 다른 문제이기 때문에 우선 차치하더라도,<br>2차원 그래프에서 2차원 함수는 최솟값을 찾기에 아주 적절한 형태를 갖추고 있다.<br>이와같은 변형을 2차원 함수의 볼록한 그릇같은 모양을 따서 convex optimization problem이라고 한다.<br>svm의 최적화 문제는 매우 다양한데, 우선 이것말고도 또 다른 최적화 방식이 있다는 것만 알아두자.</p><p><strong>도움이 됐던 자료/강의</strong></p><blockquote><p>MIT 6.034 Artificial Intelligence, Fall 2010:  <a href="https://www.youtube.com/watch?v=_PwhiWxHK8o" rel="external nofollow noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=_PwhiWxHK8o</a></p><p>Chapter 3: Support Vector machine with Math: <a href="https://medium.com/deep-math-machine-learning-ai/chapter-3-support-vector-machine-with-math-47d6193c82be" rel="external nofollow noopener noreferrer" target="_blank">https://medium.com/deep-math-machine-learning-ai/chapter-3-support-vector-machine-with-math-47d6193c82be</a></p><p>초짜 대학원생의 입장에서 이해하는 Support Vector Machine (1): <a href="http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html" rel="external nofollow noopener noreferrer" target="_blank">http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html</a></p><p>서포트 벡터 머신 (Support Vector Machine): <a href="https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/" rel="external nofollow noopener noreferrer" target="_blank">https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/image/ml/2019-03-19-svm2-1.jpeg&quot; alt=&quot;그래프&quot;&gt;&lt;/p&gt;
&lt;p&gt;다시 그래프로 돌아오자.&lt;br&gt;svm의 가장 기본적인 목표는 경계(decision boundary)에 가장 가까운 서로 다른 클래스 두
      
    
    </summary>
    
      <category term="ML" scheme="https://parkdoyeon.github.io/ml/"/>
    
    
      <category term="machine-learning" scheme="https://parkdoyeon.github.io/tags/machine-learning/"/>
    
      <category term="svm" scheme="https://parkdoyeon.github.io/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>SVM - 1. yi(x·w+b) &gt;= 1 도출하기</title>
    <link href="https://parkdoyeon.github.io/ml/ml-2019-03-19-svm/"/>
    <id>https://parkdoyeon.github.io/ml/ml-2019-03-19-svm/</id>
    <published>2019-03-19T06:09:00.000Z</published>
    <updated>2019-06-08T02:58:52.618Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image/ml/2019-03-19-svm-1.jpeg" alt="그래프"></p><p>위 그래프는 두개의 그룹을 나누는 가장 최단의 경계가 되는 서포트 벡터 라인 두개와,<br>두 그룹의 경계가 되는 점선라인(dicision boundary)을 표현하고 있다. </p><p>여기서  dicision boundary를 통과하는 범선 벡터 w와(파란색), 특정할 수 없는 어떤 벡터 u(주황색)가 있다.</p><p><img src="/image/ml/2019-03-19-svm-2.png" alt="정의"></p><p>이 둘의 내적(dot product) 값은 상수 c보다 크다고 할 수 있다고 했을때,<br>c를 이항하여 b(c=-b)로 치환하면 다음과 같다.</p><p><img src="/image/ml/2019-03-19-svm-3.png" alt="수식1"><br><img src="/image/ml/2019-03-19-svm-4.png" alt="수식2"></p><p>여기서 벡터 u가 decision boundary에 위치한 벡터 X중 하나라고 했을 때,<br>w와 X의 정의에 따라 직교하는 벡터의 내적은 0이 되므로, 아래와 같다.</p><p><img src="/image/ml/2019-03-19-svm-5.png" alt="수식3"></p><p>나아가, w와 X의 내적과 좌표계상의 위치를 조정하는 편향값(bias, Decision Boundary 그래프가 원점에서 이동한 거리)인 상수 b를 더하고,</p><p>그 합이 0이되면 벡터 X는 decision boundary에 해당하는 좌표 (x, y)값이라고 할 수 있다.<br>(다시말해, 상수 b가 0이라면 decision boundary는 원점을 지나는 그래프가 된다.)</p><p><img src="/image/ml/2019-03-19-svm-6.png" alt="수식4"></p><p>여기에 두가지 가정을 추가한다.<br>두가지 값이 1 이상이면 positive class로, -1 이하이면 negative vector class로 분류한다는 것이다.<br>값이 0이되는 식이 decision boundary의 조건식이라면,<br>값이 1, 혹은 -1이 되는 식은 각 클래스의 값과 최단거리 그래프가 되는 support vector 조건식이 된다.</p><p><img src="/image/ml/2019-03-19-svm-7.png" alt="가정"></p><p>그러나 이런 가정만으로 어떤 수학적인 법칙을 찾기에는 어려움이 있다. 이를 해소하기위해 각 항에 class값(+1, -1)인 yi를 곱한다.</p><p><img src="/image/ml/2019-03-19-svm-8.jpeg" alt="정의"></p><p>이렇게 곱셈을 하면 두개의 다른 식이 하나의 부등식으로 도출된다. (마이너스 곱을 하면 우항의 값이 플러스로 변형되고 부등호의 방향이 바뀐다)</p><p><strong>도움이 됐던 자료/강의</strong></p><blockquote><p>MIT 6.034 Artificial Intelligence, Fall 2010:  <a href="https://www.youtube.com/watch?v=_PwhiWxHK8o" rel="external nofollow noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=_PwhiWxHK8o</a></p><p>Chapter 3: Support Vector machine with Math: <a href="https://medium.com/deep-math-machine-learning-ai/chapter-3-support-vector-machine-with-math-47d6193c82be" rel="external nofollow noopener noreferrer" target="_blank">https://medium.com/deep-math-machine-learning-ai/chapter-3-support-vector-machine-with-math-47d6193c82be</a></p><p>초짜 대학원생의 입장에서 이해하는 Support Vector Machine (1): <a href="http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html" rel="external nofollow noopener noreferrer" target="_blank">http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html</a></p><p>서포트 벡터 머신 (Support Vector Machine): <a href="https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/" rel="external nofollow noopener noreferrer" target="_blank">https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/image/ml/2019-03-19-svm-1.jpeg&quot; alt=&quot;그래프&quot;&gt;&lt;/p&gt;
&lt;p&gt;위 그래프는 두개의 그룹을 나누는 가장 최단의 경계가 되는 서포트 벡터 라인 두개와,&lt;br&gt;두 그룹의 경계가 되는 점선라인(dicisio
      
    
    </summary>
    
      <category term="ML" scheme="https://parkdoyeon.github.io/ml/"/>
    
    
      <category term="machine-learning" scheme="https://parkdoyeon.github.io/tags/machine-learning/"/>
    
      <category term="svm" scheme="https://parkdoyeon.github.io/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>insert into select 사용하기</title>
    <link href="https://parkdoyeon.github.io/sql/sql-2019-03-14-insertselect/"/>
    <id>https://parkdoyeon.github.io/sql/sql-2019-03-14-insertselect/</id>
    <published>2019-03-14T09:14:00.000Z</published>
    <updated>2019-06-08T02:58:52.620Z</updated>
    
    <content type="html"><![CDATA[<p>다음과 같은 상황이 있다.</p><ol><li>table_1의 특정 컬럼값(Coupon)을 table_2에 인서트하고 싶을때.</li><li>table_2에 다른 컬럼(RegDate)이 있어서 고정된 값(‘2019-03-04’)을 넣어줘야 할때.</li><li>인서트하는 pk 컬럼(AccountNo)이 있어서 인서트 row마다 값을 임의로 지정해줘야 할때. (table_2 인덱스 넘버에서 1씩 추가 하는 것으로지정)</li></ol><p>이때 서브쿼리처럼 조회 쿼리를 생성해서 insert할 수 있다.</p><pre><code class="SQL">INSERT INTO [table_2]    (AccountNo,    Coupon,    RegDate)    (SELECT        (SELECT MAX(Seq) FROM [table_2])+(ROW_NUMBER() OVER(Order BY @@identity)),        Coupon,        &#39;2019-03-04&#39;    FROM table_1)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;다음과 같은 상황이 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;table_1의 특정 컬럼값(Coupon)을 table_2에 인서트하고 싶을때.&lt;/li&gt;
&lt;li&gt;table_2에 다른 컬럼(RegDate)이 있어서 고정된 값(‘2019-03-04’)을 넣어줘야 
      
    
    </summary>
    
      <category term="SQL" scheme="https://parkdoyeon.github.io/sql/"/>
    
    
      <category term="mssql" scheme="https://parkdoyeon.github.io/tags/mssql/"/>
    
      <category term="insert" scheme="https://parkdoyeon.github.io/tags/insert/"/>
    
  </entry>
  
  <entry>
    <title>기존 테이블에 PK키 추가하기</title>
    <link href="https://parkdoyeon.github.io/sql/sql-2019-04-22-addpk/"/>
    <id>https://parkdoyeon.github.io/sql/sql-2019-04-22-addpk/</id>
    <published>2019-03-14T09:14:00.000Z</published>
    <updated>2019-06-08T02:58:52.620Z</updated>
    
    <content type="html"><![CDATA[<p>mssql에서 PK를 추가하려면 기존의 PK를 삭제해주고 재생성해줘야한다.<br>mytable에 PK을 하나 더 추가하려고 PK 추가 구문을 아래와 같이 호출하면,<br>아래와 같이 이미 기본키가 정의되었다는 에러메세지가 나오면서 실패한다.</p><pre><code class="SQL">ALTER TABLE [dbo].[mytable] ADD  CONSTRAINT [PK_mytable] PRIMARY KEY CLUSTERED (    [otherPKColumn] ASC)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, SORT_IN_TEMPDB = OFF, IGNORE_DUP_KEY = OFF, ONLINE = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]GO</code></pre><pre><code class="SQL">메시지 1779, 수준 16, 상태 0, 줄 9테이블 &#39;mytable&#39;에 이미 기본 키가 정의되어 있습니다.메시지 1750, 수준 16, 상태 0, 줄 9제약 조건을 만들 수 없습니다. 이전 오류를 참조하십시오.</code></pre><p>때문에 아래 호출을 통해 기본키를 정의한 PK 테이블 이름을 확인한다음, </p><pre><code class="SQL">sp_helpconstraint [mytable]</code></pre><pre><code class="SQL">constraint_type constraint_name delete_action   update_action   status_enabled  status_for_replication  constraint_keysPRIMARY KEY(clustered)  PK_mytable  (n/a)  (n/a)  (n/a)  (n/a) Seq</code></pre><p>Drop문으로 날려주고 재생성해야한다.</p><pre><code class="SQL">ALTER TABLE dbo.mytable DROP CONSTRAINT PK_mytableALTER TABLE [dbo].[mytable] ADD  CONSTRAINT [PK_mytable] PRIMARY KEY CLUSTERED (    [Seq] ASC,    [otherPKColumn] ASC)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, SORT_IN_TEMPDB = OFF, IGNORE_DUP_KEY = OFF, ONLINE = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]GO</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;mssql에서 PK를 추가하려면 기존의 PK를 삭제해주고 재생성해줘야한다.&lt;br&gt;mytable에 PK을 하나 더 추가하려고 PK 추가 구문을 아래와 같이 호출하면,&lt;br&gt;아래와 같이 이미 기본키가 정의되었다는 에러메세지가 나오면서 실패한다.&lt;/p
      
    
    </summary>
    
      <category term="SQL" scheme="https://parkdoyeon.github.io/sql/"/>
    
    
      <category term="mssql" scheme="https://parkdoyeon.github.io/tags/mssql/"/>
    
      <category term="insert" scheme="https://parkdoyeon.github.io/tags/insert/"/>
    
      <category term="pk" scheme="https://parkdoyeon.github.io/tags/pk/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch - 403 index read-only 에러가 발생했을 때</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-03-10-es-readonly-err/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-03-10-es-readonly-err/</id>
    <published>2019-03-10T09:24:00.000Z</published>
    <updated>2019-06-08T02:58:52.617Z</updated>
    
    <content type="html"><![CDATA[<p>어느날 ElasticSearch index에 데이터가 제대로 들어오지 않는 것같아서 logstash의 log를 열어보니 다음과 같은 로그가 여러개 발생해 있었다.</p><pre><code class="bash">logstash.outputs.elasticsearch] retrying failed action with response code: 403 ({&quot;type&quot;=&gt;&quot;cluster_block_exception&quot;, &quot;reason&quot;=&gt;&quot;blocked by: [FORBIDDEN/12/index read-only / allow delete (api)]</code></pre><p>그래서 찾아보니 이런 내용의 글이 있었다.</p><p>(원문 페이지: <a href="https://discuss.elastic.co/t/forbidden-12-index-read-only-allow-delete-api/110282" rel="external nofollow noopener noreferrer" target="_blank">https://discuss.elastic.co/t/forbidden-12-index-read-only-allow-delete-api/110282</a>)</p><p>Edit: i think my problem is low storage. just check your storage first.</p><p>when it’s low, kibana auto changes its config to read-only mode. to deal with it, go to your dev tools console and run below command:</p><pre><code class="curl">PUT .kibana/_settings{    &quot;index&quot;: {        &quot;blocks&quot;: {        &quot;read_only_allow_delete&quot;: &quot;false&quot;        }    }}</code></pre><p>즉, ES에 용량대비 데이터가 지나치가 많이 쌓이면 키바나에서 데이터를 read-only모드로 바꾼다는 내용이다.<br>실제로 쿼리를 날리니까 문제는 해결됐다. 원문을 잘 읽어보면 ‘.kibana’ 인덱스 자체를 날리고 해결했다는 사람도 있는데,<br>대시보드 세팅이 매우 많이 진행 되었기 때문에 그럴순 없었다. (문제를 해결하는 적절한 방법 같지도 않다.)</p><p>찜찜한 마음에 더 찾아보니,<br>kibana가 설치가 되어있지 않은 ES에서도 디스크 용량이 가득차면 ES내부 옵션에서 read-only로 바뀐다고한다.<br>이럴땐 .kibana 인덱스 말고 전체(_all) 혹은 특정 인덱스 대상으로 아래와 같이 쿼리를 날리면 해결된다.</p><pre><code class="curl">PUT _all/_settings{    &quot;index&quot;: {        &quot;blocks&quot;: {        &quot;read_only_allow_delete&quot;: &quot;false&quot;        }    }}</code></pre><p>kibana 내부 옵션만으로도 데이터 전달이 되지 않는 것을 보면, ES의 insert과정에서 키바나 설정과 동기화되는 요소가 있는 것 같다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;어느날 ElasticSearch index에 데이터가 제대로 들어오지 않는 것같아서 logstash의 log를 열어보니 다음과 같은 로그가 여러개 발생해 있었다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;logstash.outputs.e
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="err" scheme="https://parkdoyeon.github.io/tags/err/"/>
    
  </entry>
  
  <entry>
    <title>Git - gitignore 즉시 적용하기</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-02-27-gitignore/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-02-27-gitignore/</id>
    <published>2019-02-27T10:23:00.000Z</published>
    <updated>2019-06-08T02:58:52.615Z</updated>
    
    <content type="html"><![CDATA[<p>gitignore 파일 생성 후에 즉시 적용하고싶다면 아래의 명령어로 캐싱된 history들을 삭제하자.</p><pre><code class="bash">git rm -r --cached .git add .git commit -m &quot;캐싱된 히스토리 삭제!&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;gitignore 파일 생성 후에 즉시 적용하고싶다면 아래의 명령어로 캐싱된 history들을 삭제하자.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;git rm -r --cached .
git add .
git commit -m &amp;quot
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="git" scheme="https://parkdoyeon.github.io/tags/git/"/>
    
      <category term="gitignore" scheme="https://parkdoyeon.github.io/tags/gitignore/"/>
    
  </entry>
  
</feed>
