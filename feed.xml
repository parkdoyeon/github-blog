<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Park Doyeon</title>
  
  
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://parkdoyeon.github.io/"/>
  <updated>2019-07-21T15:26:29.851Z</updated>
  <id>https://parkdoyeon.github.io/</id>
  
  <author>
    <name>Park Doyeon</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>big sort 문제 풀기 - sort()함수에 대한 고찰</title>
    <link href="https://parkdoyeon.github.io/python/python-2019-07-21-sort/"/>
    <id>https://parkdoyeon.github.io/python/python-2019-07-21-sort/</id>
    <published>2019-07-21T07:29:01.000Z</published>
    <updated>2019-07-21T15:26:29.851Z</updated>
    
    <content type="html"><![CDATA[<p>hackerrank에서 string으로 이루어진 무작위 순서의 리스트를 정렬하는 <a href="https://www.hackerrank.com/challenges/big-sorting/" rel="external nofollow noopener noreferrer" target="_blank">big-sorting</a>문제를 풀었다. 내장된 sort()함수를 쓰면 안될 것 같아 직접 선택정렬을 활용한 sort함수를 구현했는데 케이스 절반만 통과했다.</p><pre><code class="python">def bigSorting(unsorted):    for i in range(len(unsorted)-1, -1, -1):        lgidx, largest = i, unsorted[i]        j = -1        while i+j &gt;= 0:            if len(unsorted[j+i]) &gt; len(largest): # 자릿수가 다르면 바로 순서 변경                lgidx = j+i                largest = unsorted[j+i]            elif len(unsorted[j+i]) == len(largest):  # 자릿수가 같으면 숫자로 캐스팅한 다음 비교                if int(unsorted[j+i]) &gt; int(largest):                    lgidx = j+i                    largest = unsorted[j+i]            j-=1        if unsorted[i] != largest:            temp = unsorted[i]            unsorted[i] = largest            unsorted[lgidx] = temp    return unsorted</code></pre><p>이 문제의 핵심은 string에서 int로 캐스팅할때 발생하는 비용처리이다. 내 코드는 자릿수가 다른 경우만 처리한다는 점, 그리고 선택정렬 자체가 효율적이지 못했던 점이 문제였던 것 같다. 꽤 오랜시간을 들였는데도 답이 나오지 않아서 discussion을 읽기 시작했는데, 알지 못했던 사실들이 많았다.</p><h3 id="sort-는-꽤-훌륭한-구현속도를-자랑하며-sorted-와-성능상-큰-차이가-없다"><a href="#sort-는-꽤-훌륭한-구현속도를-자랑하며-sorted-와-성능상-큰-차이가-없다" class="headerlink" title="sort()는 꽤 훌륭한 구현속도를 자랑하며, sorted()와 성능상 큰 차이가 없다."></a>sort()는 꽤 훌륭한 구현속도를 자랑하며, sorted()와 성능상 큰 차이가 없다.</h3><p>sort()만 사용해도 테스트 케이스는 3문제를 제외하고(숫자 대소 확인이 안되어서 wrong answer가 된다) 모두 통과한다. 정렬은 둘 중 어느 함수를 써도 상관없다. 차이라면 sort()는 배열 원본의 순서를 변경하지만 sorted는 정렬된 리스트를 반환한다는 점이다.</p><pre><code class="python">arr.sort()copy_arr = sorted(arr)</code></pre><h3 id="int에서-string으로-캐스팅할-때-비용이-반대의-경우보다-훨씬-크다"><a href="#int에서-string으로-캐스팅할-때-비용이-반대의-경우보다-훨씬-크다" class="headerlink" title="int에서 string으로 캐스팅할 때 비용이 반대의 경우보다 훨씬 크다."></a>int에서 string으로 캐스팅할 때 비용이 반대의 경우보다 훨씬 크다.</h3><p>big sorting 문제풀이를 하려면 비교를 위해 필연적으로 string을 int로 변환하고, print구문으로 출력을 위해 string으로 변환하는 과정을 거친다. 여기서 숫자간 대소비교를 위해 int캐스팅 하는 과정은 비교적 빠르게 이루어지지만, 비교를 위해 변경한 int값을 string으로 바꾸는것은 꽤 오래걸린다.</p><h3 id="해법-sort-key-int"><a href="#해법-sort-key-int" class="headerlink" title="해법: sort(key=int)"></a>해법: sort(key=int)</h3><p>결론적으로 캐스팅 과정을 최소화 해야하는데, 3.6의 sort함수는 비교를 위한 ‘선택적 casting’을 지원한다. 즉, 필요시에만 대소비교를 위해 캐스팅을 하고, 본래의 원소는 string으로 배열된다.</p><pre><code class="python">arr.sort(key=int)copy_arr = sorted(arr, key=int)</code></pre><h3 id="더-좋은-해결-sort-key-len"><a href="#더-좋은-해결-sort-key-len" class="headerlink" title="더 좋은 해결!: sort(key=len)"></a>더 좋은 해결!: sort(key=len)</h3><p>하지만 위의 경우도 여전히 캐스팅은 발생한다. 캐스팅 없이 정렬할때의 문제는 숫자 대소인데, string기준으로 sorting을 한 다음에 key값으로 int가 아니라 문자열의 길이로 한번 더 sorting 해주면 통과할 수 있다.</p><pre><code class="python">arr = sorted(sorted(arr), key=len)</code></pre><p>그러나 이건 제출의 문제이고, key값에 비교 람다함수를 넣어서 한번의 정렬만 일어나게 하면 훨씬 빠르게 연산이 일어난다.</p><pre><code class="python">import timeitdef bigSortinglen(unsorted):    return sorted(unsorted, key=lambda x: (len(x), x))def bigSortingint(unsorted):    return sorted(unsorted, key=lambda x: int(x))print(    &quot;bigSorting - len:&quot;,    timeit.timeit(&quot;bigSortinglen(unsorted)&quot;,     globals=globals(),     number=1),)print(    &quot;bigSorting - int:&quot;,    timeit.timeit(&quot;bigSortingint(unsorted)&quot;,     globals=globals(),     number=1),)</code></pre><p>실제로 timeit 라이브러리를 통해 시간을 비교하면 550배나 더 빠르다는 것을 알 수 있다.<br><code>bigSorting - len: 0.007199285000751843</code><br><code>bigSorting - int: 3.989389060998292</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;hackerrank에서 string으로 이루어진 무작위 순서의 리스트를 정렬하는 &lt;a href=&quot;https://www.hackerrank.com/challenges/big-sorting/&quot; rel=&quot;external nofollow noopener
      
    
    </summary>
    
      <category term="Python" scheme="https://parkdoyeon.github.io/python/"/>
    
    
      <category term="python" scheme="https://parkdoyeon.github.io/tags/python/"/>
    
      <category term="algorithm" scheme="https://parkdoyeon.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>윈도우 파워쉘 권한 변경하기</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-07-10-powershell-auth/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-07-10-powershell-auth/</id>
    <published>2019-07-10T09:02:31.000Z</published>
    <updated>2019-07-13T09:32:43.641Z</updated>
    
    <content type="html"><![CDATA[<p>간혹 윈도우 2009 정도되는 서버 파워쉘에서 스크립트 파일 실행시 아래와 같이 스크립트 에러메세지가 출력 되는경우가 있다.</p><pre><code class="PowerShell">오류: 이 시스템에서 스크립트를 실행할 수 없으므로 [script] 파일을 로드할 수 없습니다.</code></pre><p>관리자 권한으로 파워쉘 실행하고, 아래의 명령어로 실행 정책을 확인한다. </p><pre><code class="PowerShell">PS &gt; Get-ExecutionPolicy</code></pre><p>리턴된 값이 Restricted이면 외부 스크립트 실행이 안되므로 UnRestricted나 RemoteSigned으로 바꿔주면 된다.</p><pre><code class="PowerShell">PS &gt; Set-ExecutionPolicy RemoteSigned</code></pre><p>RemoteSigned는 외부 스크립트에 모든 실행 권한을 주고, UnRestricted는 일부 스크립트에서 실행가능하다. 실행할때 ExecutionPolicy의 파라미터 값을 UnRestricted로 주면된다. 가령 Metricbeat의 서비스 인스톨 스크립트는 UnRestricted레벨을 주면 정상적으로 실행된다.</p><pre><code class="PowerShell">PowerShell.exe -ExecutionPolicy UnRestricted -File .\install-service-metricbeat.ps1.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;간혹 윈도우 2009 정도되는 서버 파워쉘에서 스크립트 파일 실행시 아래와 같이 스크립트 에러메세지가 출력 되는경우가 있다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;PowerShell&quot;&gt;오류: 이 시스템에서 스크립트를 실행할 수 없으므로 [scr
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="window" scheme="https://parkdoyeon.github.io/tags/window/"/>
    
      <category term="powershell" scheme="https://parkdoyeon.github.io/tags/powershell/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch - unassigned shard 문제 해결 (3) replica 숫자가 부적절할때</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-06-27-es-replica/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-06-27-es-replica/</id>
    <published>2019-06-27T07:47:13.000Z</published>
    <updated>2019-06-27T15:33:15.454Z</updated>
    
    <content type="html"><![CDATA[<p>엘라스틱서치 테스트 환경에서 일어난 일이다. 마스터노드 1대만 단독으로 서비스가 올라가있는데, 어느 시점부터(아마도 es 버전을 올린 시점부터) index health status가 yellow로 바뀌었다. 확인해보니, 모든 인덱스에서 replica shard만 할당이 되지 못하고 있었다. 이유를 쿼리했더니 동일한 샤드가 있는 곳엔 샤드할당이 되지않는다는 에러메세지가 나왔다.</p><pre><code class="json">GET /_cluster/allocation/explain{    //...생략    cannot allocate because allocation is not permitted to any of the nodes that hold an in-sync shard copy    //...생략}</code></pre><p>좀 더 찾아보니, 스택오버플로우에 <a href="https://stackoverflow.com/questions/37302611/elasticsearch-doesnt-allow-to-allocate-unassigned-shard" rel="external nofollow noopener noreferrer" target="_blank">나와 비슷한 상황</a>인 사람이 있었다. replica는 말그대로 복제 샤드이기 때문에 동일한 노드에 배치될 수 없고, 또 다른 노드에 배치되어야 한다는 답변이 있었다. 즉, 복제샤드가 필요하면 노드를 추가 해야하고, 아니면 복제샤드 갯수 설정을 더 낮게 바꿔야한다는 것이다. </p><p>복제 샤드를 올바르게 설정하려면 “전체 노드 갯수 &gt;원본샤드 노드(1) + 복제샤드 갯수”가 성립해야 한다. ES가 기본값으로 설정하는 샤드의 갯수는 5개, 복제 샤드의 갯수는 1개이다. 테스트환경처럼 단독으로 ES 노드를 운영하는 상황에서는 복제샤드의 갯수를 0으로 맞춰줘야 status를 green으로 유지할 수 있다.</p><p>다행히도 복제샤드에 대한 설정은 이미 생성된 인덱스에도 적용할 수 있다. 다음과같이 쿼리하면 된다.</p><pre><code class="json">PUT /index_name_*/_settings{  &quot;index&quot;: {    &quot;number_of_replicas&quot;: 0  }}</code></pre><p>그리고, 앞으로 생성될 인덱스에 일괄적용하고싶다면 아래와 같이 <a href="/elk/elk-2019-02-27-es-mapping">템플릿을 통해</a> 지정하면 된다.</p><pre><code class="json">GET _template/myindex_shards_control{  &quot;index_patterns&quot;: &quot;index_name_*&quot;,  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1,    &quot;number_of_replicas&quot;: 0  }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;엘라스틱서치 테스트 환경에서 일어난 일이다. 마스터노드 1대만 단독으로 서비스가 올라가있는데, 어느 시점부터(아마도 es 버전을 올린 시점부터) index health status가 yellow로 바뀌었다. 확인해보니, 모든 인덱스에서 repli
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch 7.2에 한국어 분석기 Nori 플러그인 설치하기</title>
    <link href="https://parkdoyeon.github.io/uncategorized/elk-2019-06-27-es-nori/"/>
    <id>https://parkdoyeon.github.io/uncategorized/elk-2019-06-27-es-nori/</id>
    <published>2019-06-27T02:18:32.000Z</published>
    <updated>2019-07-09T13:36:23.201Z</updated>
    
    <content type="html"><![CDATA[<p>엘라스틱서치가 검색엔진으로서 한국어를 올바르게 인식하도록 하려면 한국어 분석기가 필요하다. 엘라스틱서치 6.4부터 공식적으로 제공하는 한국어 분석 플러그인 Nori는 기본 플러그인이 아니므로 번거롭지만 별도로 설치해줘야한다. 나는 도커로 서버를 운용하기때문에, 엘라스틱서치 공식 도커 이미지에 플러그인만 설치해서 다시 빌드했다.</p><pre><code class="dockerfile">FROM docker.elastic.co/elasticsearch/elasticsearch:7.2.0RUN [&quot;bin/elasticsearch-plugin&quot;, &quot;install&quot;, &quot;analysis-nori&quot;]CMD bin/elasticsearch</code></pre><p>설치후에는 플러그인 동작을 노리에서 제공하는 기본 분석기로 테스트를 해볼 수 있다.</p><pre><code class="json">POST _analyze{  &quot;explain&quot;: true,   &quot;analyzer&quot;: &quot;nori&quot;,  &quot;text&quot;: &quot;&lt;p&gt;젤다의전설은 링크가 주인공이다.&lt;/p&gt;&quot;,  &quot;attributes&quot; : [&quot;posType&quot;, &quot;leftPOS&quot;, &quot;rightPOS&quot;, &quot;morphemes&quot;, &quot;reading&quot;] //해당 컬럼이 없으면 전체 필드가 다 노출된다.}// Response 200{  &quot;detail&quot; : {    &quot;custom_analyzer&quot; : false,    &quot;analyzer&quot; : {      &quot;name&quot; : &quot;org.apache.lucene.analysis.ko.KoreanAnalyzer&quot;,      &quot;tokens&quot; : [        {          &quot;token&quot; : &quot;p&quot;,          &quot;start_offset&quot; : 1,          &quot;end_offset&quot; : 2,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 0,          &quot;leftPOS&quot; : &quot;SL(Foreign language)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;SL(Foreign language)&quot;        },        {          &quot;token&quot; : &quot;젤다&quot;,          &quot;start_offset&quot; : 3,          &quot;end_offset&quot; : 5,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 1,          &quot;leftPOS&quot; : &quot;NNP(Proper Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNP(Proper Noun)&quot;        },        {          &quot;token&quot; : &quot;전설&quot;,          &quot;start_offset&quot; : 6,          &quot;end_offset&quot; : 8,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 3,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;링크&quot;,          &quot;start_offset&quot; : 10,          &quot;end_offset&quot; : 12,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 5,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;주인&quot;,          &quot;start_offset&quot; : 14,          &quot;end_offset&quot; : 16,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 7,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;공&quot;,          &quot;start_offset&quot; : 16,          &quot;end_offset&quot; : 17,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 8,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;이&quot;,          &quot;start_offset&quot; : 17,          &quot;end_offset&quot; : 18,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 9,          &quot;leftPOS&quot; : &quot;VCP(Positive designator)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;VCP(Positive designator)&quot;        },        {          &quot;token&quot; : &quot;p&quot;,          &quot;start_offset&quot; : 22,          &quot;end_offset&quot; : 23,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 11,          &quot;leftPOS&quot; : &quot;SL(Foreign language)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;SL(Foreign language)&quot;        }      ]    }  }}</code></pre><h1 id="커스터마이즈-하기"><a href="#커스터마이즈-하기" class="headerlink" title="커스터마이즈 하기"></a>커스터마이즈 하기</h1><p>검색결과를 코드로직에서 가공할수도 있지만, 커스텀 분석기를 만들어 더 효율적으로 결과의 내용을 변경할 수 있다. 커스텀 분석기가 잘 적용되는지 테스트를 하기위해 직접 데이터가 있는 인덱스에 붙이지 않고 샘플로 <code>my-custom-analyzer</code>인덱스를 생성한다.</p><pre><code class="json">PUT my-custom-analyzer{    &quot;settings&quot;:{        &quot;number_of_shards&quot;: 5,        &quot;number_of_replicas&quot;: 0,        &quot;analysis&quot;:{            &quot;tokenizer&quot;:{                &quot;kr_bbs_tokenizer&quot;:{                    &quot;type&quot;:&quot;nori_tokenizer&quot;,                    &quot;decompound_mode&quot;:&quot;mixed&quot;,                    //&quot;user_dictionary_rules&quot;: [&quot;젤다의전설 젤다 의 전설&quot;, &quot;성남시 성남 시&quot;, &quot;링크&quot;], 배열로 등록할수도 있고, 아래와 같이 직접 파일로 등록할 수도 있다.                    &quot;user_dictionary&quot;:&quot;user_dictionary.txt&quot;                }            },            &quot;analyzer&quot;:{                &quot;nori&quot;:{                    &quot;type&quot;:&quot;custom&quot;,                    &quot;tokenizer&quot;:&quot;kr_bbs_tokenizer&quot;                }            }        }    }}</code></pre><p>user_dictionary는 단어로 인식할 값들이 들어있는 배열이다. 텍스트 파일의 경우 개행을 통해 단어를, 띄어쓰기를 통해 형식을 구분한다. 띄어쓰기는 첫번째 음절을 명사로, 두번째 음절을 복합명사로 등록한다.</p><pre><code class="txt">성남시 성남 시젤다의전설 젤다 의 전설링크</code></pre><p>해당 파일은 <code>$ELASTICSEARCH-HOME/config/</code>경로에 넣어놓고 등록하면 된다. 도커를 통해 텍스트파일을 마운트하고-&gt;분석기에 파일 등록하고 -&gt;사전 내용 수정을 했는데,커스텀 분석기가 파일이 변경되면 바로 감지를 못하는 것같다. 완성된 사전을 분석기 등록시에 넣어줘야하는지 조금더 확인이 필요한 것같다.</p><p><em>주의! (2019-07-06 업데이트)</em><br>노드가 여러개인 경우 각 ES 인스턴스 경로마다 사용자 정의사전 파일을 추가해야한다. 분명히 인덱스 매핑 템플릿 설정은 정상적으로 되는데(경로에 해당파일 없으면 설정도 되지 않는다) ES에서 계속 IOException 로그와 함께 복제 샤드가 샤딩이 잘 안되길래 파일명 바꿔가며 한참 삽질을 한 후에야 깨달았다.</p><p>커스텀 분석기를 통해 사전을 적용한 형태소분석 결과값은 아래와 같다.</p><pre><code class="json">POST my-custom-analyzer/_analyze{  &quot;explain&quot;: true,   &quot;analyzer&quot;: &quot;nori&quot;,  &quot;text&quot;: &quot;&lt;p&gt;젤다의전설은 링크가 주인공이다.&lt;/p&gt;&quot;,  &quot;attributes&quot; : [&quot;posType&quot;, &quot;leftPOS&quot;, &quot;rightPOS&quot;, &quot;morphemes&quot;, &quot;reading&quot;]}// Response 200{  &quot;detail&quot; : {    &quot;custom_analyzer&quot; : true,    &quot;charfilters&quot; : [ ],    &quot;tokenizer&quot; : {      &quot;name&quot; : &quot;my_custom_tokenizer&quot;,      &quot;tokens&quot; : [        {          &quot;token&quot; : &quot;p&quot;,          &quot;start_offset&quot; : 1,          &quot;end_offset&quot; : 2,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 0,          &quot;leftPOS&quot; : &quot;SL(Foreign language)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;SL(Foreign language)&quot;        },        {          &quot;token&quot; : &quot;젤다의전설&quot;,          &quot;start_offset&quot; : 3,          &quot;end_offset&quot; : 8,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 1,          &quot;positionLength&quot; : 3,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : &quot;젤다/NNG(General Noun)+의/NNG(General Noun)+전설/NNG(General Noun)&quot;,          &quot;posType&quot; : &quot;COMPOUND&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;젤다&quot;,          &quot;start_offset&quot; : 3,          &quot;end_offset&quot; : 5,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 1,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;의&quot;,          &quot;start_offset&quot; : 5,          &quot;end_offset&quot; : 6,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 2,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;전설&quot;,          &quot;start_offset&quot; : 6,          &quot;end_offset&quot; : 8,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 3,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;은&quot;,          &quot;start_offset&quot; : 8,          &quot;end_offset&quot; : 9,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 4,          &quot;leftPOS&quot; : &quot;J(Ending Particle)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;J(Ending Particle)&quot;        },        {          &quot;token&quot; : &quot;링크&quot;,          &quot;start_offset&quot; : 10,          &quot;end_offset&quot; : 12,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 5,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;가&quot;,          &quot;start_offset&quot; : 12,          &quot;end_offset&quot; : 13,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 6,          &quot;leftPOS&quot; : &quot;J(Ending Particle)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;J(Ending Particle)&quot;        },        {          &quot;token&quot; : &quot;주인공&quot;,          &quot;start_offset&quot; : 14,          &quot;end_offset&quot; : 17,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 7,          &quot;positionLength&quot; : 2,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : &quot;주인/NNG(General Noun)+공/NNG(General Noun)&quot;,          &quot;posType&quot; : &quot;COMPOUND&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;주인&quot;,          &quot;start_offset&quot; : 14,          &quot;end_offset&quot; : 16,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 7,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;공&quot;,          &quot;start_offset&quot; : 16,          &quot;end_offset&quot; : 17,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 8,          &quot;leftPOS&quot; : &quot;NNG(General Noun)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;NNG(General Noun)&quot;        },        {          &quot;token&quot; : &quot;이&quot;,          &quot;start_offset&quot; : 17,          &quot;end_offset&quot; : 18,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 9,          &quot;leftPOS&quot; : &quot;VCP(Positive designator)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;VCP(Positive designator)&quot;        },        {          &quot;token&quot; : &quot;다&quot;,          &quot;start_offset&quot; : 18,          &quot;end_offset&quot; : 19,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 10,          &quot;leftPOS&quot; : &quot;E(Verbal endings)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;E(Verbal endings)&quot;        },        {          &quot;token&quot; : &quot;p&quot;,          &quot;start_offset&quot; : 22,          &quot;end_offset&quot; : 23,          &quot;type&quot; : &quot;word&quot;,          &quot;position&quot; : 11,          &quot;leftPOS&quot; : &quot;SL(Foreign language)&quot;,          &quot;morphemes&quot; : null,          &quot;posType&quot; : &quot;MORPHEME&quot;,          &quot;reading&quot; : null,          &quot;rightPOS&quot; : &quot;SL(Foreign language)&quot;        }      ]    },    &quot;tokenfilters&quot; : [ ]  }}</code></pre><h1 id="필터-세팅하기-nori-part-of-speech"><a href="#필터-세팅하기-nori-part-of-speech" class="headerlink" title="필터 세팅하기: nori_part_of_speech"></a>필터 세팅하기: nori_part_of_speech</h1><p>위에 분석결과를 보면 알 수 있듯이, 한국어의 조사같은 경우는 결과값으로서 의미가 없기때문에 처음부터 분석결과에 제외하는 것이 좋다. 방금 커스터마이즈로 추가한 인덱스에 <code>filter</code>필드의 값으로 필터링할 품사를 넣어주면 된다. 품사에 대한 정보는 <a href="http://lucene.apache.org/core/8_0_0/analyzers-nori/org/apache/lucene/analysis/ko/POS.Tag.html" rel="external nofollow noopener noreferrer" target="_blank">루씬 API문서</a>를 참조하면되고, 설명은 <a href="https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-nori-speech.html" rel="external nofollow noopener noreferrer" target="_blank">nori 공식문서</a>를 참고하면 된다. 하지만 생선된 인덱스를 변경하기 위해서는</p><ol><li><code>_close</code>으로 인덱스를 닫은 다음</li><li>PUT 메소드의 _settings 쿼리를 통해 분석기를 변경하고 <ul><li>filter필드를 추가하고, analyzer필드 내부에 filter값을 지정해주면 된다.</li></ul></li><li><code>_open</code>을 통해 다시 열어줘야한다.</li></ol><pre><code class="json">POST my-custom-analyzer/_closePOST my-custom-analyzer/_settings{    &quot;analysis&quot;:{        &quot;tokenizer&quot;:{            &quot;my_custom_tokenizer&quot;:{                &quot;type&quot;:&quot;nori_tokenizer&quot;,                &quot;decompound_mode&quot;:&quot;mixed&quot;,                &quot;user_dictionary&quot;:&quot;user_dictionary.txt&quot;            }        },        &quot;analyzer&quot;:{            &quot;nori&quot;:{                &quot;type&quot;:&quot;custom&quot;,                &quot;tokenizer&quot;:&quot;my_custom_tokenizer&quot;,                &quot;filter&quot;: [                    &quot;nori_posfilter&quot;                ]            }        },        &quot;filter&quot;:{            &quot;nori_posfilter&quot;:{                &quot;type&quot;:&quot;nori_part_of_speech&quot;,                &quot;stoptags&quot;: [                    &quot;E&quot;,&quot;IC&quot;,&quot;J&quot;,&quot;MAG&quot;,&quot;MM&quot;,&quot;NA&quot;,&quot;NR&quot;,&quot;SC&quot;,                    &quot;SE&quot;,&quot;SF&quot;,&quot;SH&quot;,&quot;SL&quot;,&quot;SN&quot;,&quot;SP&quot;,&quot;SSC&quot;,&quot;SSO&quot;,                    &quot;SY&quot;,&quot;UNA&quot;,&quot;UNKNOWN&quot;,&quot;VA&quot;,&quot;VCN&quot;,&quot;VCP&quot;,&quot;VSV&quot;,                    &quot;VV&quot;,&quot;VX&quot;,&quot;XPN&quot;,&quot;XR&quot;,&quot;XSA&quot;,&quot;XSN&quot;,&quot;XSV&quot;                ]            }        }    }}POST my-custom-analyzer/_open</code></pre><p>그럼 이제 의도한대로 필터링이 되었는지 확인해보자. anlayze쿼리에 <code>explain: true</code>값이 있으면 필터링이 되지 않으므로 반드시 제외하고 쿼리를 날리자. </p><pre><code class="json">POST my-custom-analyzer/_analyze{  &quot;analyzer&quot;:&quot;nori&quot;,  &quot;text&quot;: &quot;&lt;p&gt;젤다의전설은 링크가 주인공이다.&lt;/p&gt;&quot;}//Response 200{  &quot;tokens&quot; : [    {      &quot;token&quot; : &quot;젤다의전설&quot;,      &quot;start_offset&quot; : 3,      &quot;end_offset&quot; : 8,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 1,      &quot;positionLength&quot; : 3    },    {      &quot;token&quot; : &quot;젤다&quot;,      &quot;start_offset&quot; : 3,      &quot;end_offset&quot; : 5,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 1    },    {      &quot;token&quot; : &quot;의&quot;,      &quot;start_offset&quot; : 5,      &quot;end_offset&quot; : 6,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 2    },    {      &quot;token&quot; : &quot;전설&quot;,      &quot;start_offset&quot; : 6,      &quot;end_offset&quot; : 8,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 3    },    {      &quot;token&quot; : &quot;링크&quot;,      &quot;start_offset&quot; : 10,      &quot;end_offset&quot; : 12,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 5    },    {      &quot;token&quot; : &quot;주인공&quot;,      &quot;start_offset&quot; : 14,      &quot;end_offset&quot; : 17,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 7,      &quot;positionLength&quot; : 2    },    {      &quot;token&quot; : &quot;주인&quot;,      &quot;start_offset&quot; : 14,      &quot;end_offset&quot; : 16,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 7    },    {      &quot;token&quot; : &quot;공&quot;,      &quot;start_offset&quot; : 16,      &quot;end_offset&quot; : 17,      &quot;type&quot; : &quot;word&quot;,      &quot;position&quot; : 8    }  ]}</code></pre><h1 id="템플릿-생성"><a href="#템플릿-생성" class="headerlink" title="템플릿 생성"></a>템플릿 생성</h1><p>이제 테스트해본 설정을 그대로 인덱스 템플릿에 붙이면된다.</p><pre><code class="json">PUT _template/kr-board-analyzer-set{  &quot;index_patterns&quot;: &quot;kr-board-*&quot;,  &quot;settings&quot;:{    &quot;index&quot;: {      &quot;analysis&quot;:{        &quot;tokenizer&quot;:{            &quot;custom_tokenizer&quot;:{                &quot;type&quot;:&quot;nori_tokenizer&quot;,                &quot;decompound_mode&quot;:&quot;mixed&quot;,                &quot;user_dictionary&quot;:&quot;user_dictionary.txt&quot;            }        },        &quot;analyzer&quot;:{          &quot;custom_analyzer&quot;:{            &quot;type&quot;:&quot;custom&quot;,            &quot;tokenizer&quot;:&quot;custom_tokenizer&quot;,            &quot;filter&quot;: [                &quot;custom_posfilter&quot;            ]          }        },        &quot;filter&quot;:{          &quot;custom_posfilter&quot;:{            &quot;type&quot;:&quot;nori_part_of_speech&quot;,            &quot;stoptags&quot;: [                &quot;E&quot;,&quot;IC&quot;,&quot;J&quot;,&quot;MAG&quot;,&quot;MM&quot;,&quot;NA&quot;,&quot;NR&quot;,&quot;SC&quot;,                &quot;SE&quot;,&quot;SF&quot;,&quot;SH&quot;,&quot;SL&quot;,&quot;SN&quot;,&quot;SP&quot;,&quot;SSC&quot;,&quot;SSO&quot;,                &quot;SY&quot;,&quot;UNA&quot;,&quot;UNKNOWN&quot;,&quot;VA&quot;,&quot;VCN&quot;,&quot;VCP&quot;,&quot;VSV&quot;,                &quot;VV&quot;,&quot;VX&quot;,&quot;XPN&quot;,&quot;XR&quot;,&quot;XSA&quot;,&quot;XSN&quot;,&quot;XSV&quot;            ]          }        }      }    }  },  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;obj&quot;: {        &quot;properties&quot;: {          &quot;Target&quot;: {            &quot;properties&quot;: {              &quot;model&quot;: {                &quot;properties&quot;: {                  &quot;Contents&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;custom_analyzer&quot; },                  &quot;Title&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;custom_analyzer&quot; }                }              }            }          }        }      }    }  }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;엘라스틱서치가 검색엔진으로서 한국어를 올바르게 인식하도록 하려면 한국어 분석기가 필요하다. 엘라스틱서치 6.4부터 공식적으로 제공하는 한국어 분석 플러그인 Nori는 기본 플러그인이 아니므로 번거롭지만 별도로 설치해줘야한다. 나는 도커로 서버를 
      
    
    </summary>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="nlp" scheme="https://parkdoyeon.github.io/tags/nlp/"/>
    
      <category term="nori" scheme="https://parkdoyeon.github.io/tags/nori/"/>
    
  </entry>
  
  <entry>
    <title>Docker 로그로 서버 용량이 꽉찼을 때</title>
    <link href="https://parkdoyeon.github.io/docker/docker-2019-06-18-docker-logrotate/"/>
    <id>https://parkdoyeon.github.io/docker/docker-2019-06-18-docker-logrotate/</id>
    <published>2019-06-18T06:57:18.000Z</published>
    <updated>2019-06-27T15:33:15.452Z</updated>
    
    <content type="html"><![CDATA[<h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>평소와 같이 logstash에 파이프라인을 추가하려고 서버에 들어갔다가,<br>자동완성을 하려고 배시에 tab키를 눌렀더니 다음과 같은 텍스트가 출력됐다.</p><pre><code class="bash">$ cd p-bash: cannot create temp file for here-document: No space left on device</code></pre><p>남은 용량이 얼마나 있는지 확인하려고 <code>du</code>명령어를 쳤다. 보아하니 도커 디스크로 마운트된 디렉토리에 문제가 있는 것 같았다.</p><pre><code class="bash">$ df -hFilesystem                              Size  Used Avail Use% Mounted onudev                                    3.9G     0  3.9G   0% /devtmpfs                                   798M   79M  720M  10% /run/dev/mapper/[HOST이름]--vg-root   90G  4.3G   82G   6% /tmpfs                                   3.9G     0  3.9G   0% /dev/shmtmpfs                                   5.0M     0  5.0M   0% /run/locktmpfs                                   3.9G     0  3.9G   0% /sys/fs/cgroup/dev/sda1                               472M  153M  295M  35% /boottmpfs                                   798M     0  798M   0% /run/user/1003overlay                                  90G   90G     0 100% /var/lib/docker/overlay2/a5d0d5380f3e692bccb926c9fbf1c07ba6abc73db094b0e526d71aa19fd51537/mergedshm                                      64M     0   64M   0% /var/lib/docker/containers/ef5745582de101dddc056068c78e024388169af634315348427a80d59148a324/mounts/shm</code></pre><h1 id="원인"><a href="#원인" class="headerlink" title="원인"></a>원인</h1><p>도커의 컨테이너들로부터 출력되는 모든 로그들은 다 json파일로 파일시스템에 남는다.<br>즉, <code>/var/lib/docker/containers/*/*.log</code>와 같은 경로에 컨테이너의 ID로 된 디렉토리에 개별로 저장된다.<br>이 파일들은 관리가 되지 않으면 서서히 디스크 용량을 차지해서 disk full현상을 일으킬 수 있다.</p><p>나의 경우, logstash의 모든 파서들이 파싱된 로그를 stdout으로 출력하다보니 며칠만에 약 90G가 넘는 로그파일때문에 3-4일만에 서버 디스크가 꽉 찼었다.<br>(F.Y.I. 도커로 인한 disk full이 logstash를 운영하는데 별다른 영향을 주진 않았다.)</p><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><p>해결방법은 log파일 관리를 자동화 하면 되는데,</p><ol><li>크론으로 json파일을 삭제할수도 있고</li><li>logrotate를 설치해서 실행시킬수도 있다. </li><li>하지만 나는 폐쇄된 네트워크에서 서버세팅을 해야하기때문에, <a href="https://docs.docker.com/config/containers/logging/configure/" rel="external nofollow noopener noreferrer" target="_blank">도커에 내장된 로그 설정</a>을 통해 로그 관리 세팅을 했다.</li></ol><h1 id="방법"><a href="#방법" class="headerlink" title="방법"></a>방법</h1><p>참고로, 내가 채택한 3번 방법은 도커서비스와 컨테이너를 내렸다가 새로 생성해줘야 적용이 되는 번거로움이 있다.</p><ol><li>아래 경로로 다음과 같은 내용의 설정파일을 하나 만든다. 있으면 수정하고, 없으면 새로 만들어주면 된다.<pre><code class="bash"> $ vi /etc/docker/daemon.json { &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: {     &quot;max-size&quot;: &quot;100m&quot;,         &quot;max-file&quot;: &quot;3&quot;         } } </code></pre></li><li>도커 서비스를 재시작한다 (나는 스페이스 4개로 indentation을 구분했고, 이때 쉼표를 더 입력하거나 하면 시스템이 시작하지 않으므로 주의해야한다.)<pre><code class="bash"> $ systemctl restart docker</code></pre></li><li>컨테이너를 다시 생성한다</li></ol><p>설정이 적용된 컨테이너의 <code>/var/lib/docker/containers/*</code> 디렉토리 모습이다.</p><pre><code class="bash">$ ls9967b82d7c4059e1fb96ef9f20dc8c8738bf58e6e7418c680ac81019e5c964ec-json.log    checkpoints      hostname  resolv.conf9967b82d7c4059e1fb96ef9f20dc8c8738bf58e6e7418c680ac81019e5c964ec-json.log.1  config.v2.json   hosts     resolv.conf.hash9967b82d7c4059e1fb96ef9f20dc8c8738bf58e6e7418c680ac81019e5c964ec-json.log.2  hostconfig.json  mounts</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;문제&quot;&gt;&lt;a href=&quot;#문제&quot; class=&quot;headerlink&quot; title=&quot;문제&quot;&gt;&lt;/a&gt;문제&lt;/h1&gt;&lt;p&gt;평소와 같이 logstash에 파이프라인을 추가하려고 서버에 들어갔다가,&lt;br&gt;자동완성을 하려고 배시에 tab키를 눌렀더니 다
      
    
    </summary>
    
      <category term="Docker" scheme="https://parkdoyeon.github.io/docker/"/>
    
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="container" scheme="https://parkdoyeon.github.io/tags/container/"/>
    
      <category term="logrotate" scheme="https://parkdoyeon.github.io/tags/logrotate/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch - unassigned shard 문제 해결 (2) 노드간 버전문제</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-06-18-es-version/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-06-18-es-version/</id>
    <published>2019-06-18T02:37:18.000Z</published>
    <updated>2019-06-27T15:33:15.454Z</updated>
    
    <content type="html"><![CDATA[<h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Elasticsearch 홈페이지에서 공식 docker 이미지를 받아 새로운 노드가 되는 서버를 구성했는데,<br>그새 버전이 올라서 내가 사용하던 6.7.0이아닌 6.7.1이 설치되었다.</p><p>즉, 마스터를 포함한 두개의 서버에서는 6.7.0 이 실행되고, 새로 추가한 서버에서만 6.7.1의 도커 이미지가 도는 상태였다.<br>버전간 차이는 끝 자리수 +1이니 변화도 미미하고,<br>실제로 실행을 해도 크게 에러메세지나 경고메세지가 발생하지 않아서 하루정도 가만히 두고 있었다.</p><h1 id="원인"><a href="#원인" class="headerlink" title="원인"></a>원인</h1><p>그런데 추가한 노드로 샤드가 assign이 되지 않아서, 이유를 확인하려고 쿼리를 날렸다. </p><pre><code class="curl">GET /_cluster/allocation/explain</code></pre><p>위 쿼리를 날리면 shard정보와 cluster_info, 그리고 node 정보가 출력이 된다.<br>각 노드별 assign이 안되는 사유가 출력되고, 그 출력 사유가 실제 usassign에 있어서 얼만큼의 가중치(weight)를 갖는지도 표시된다. 나의 경우 node_version이 문제였고, 새로 세팅한 6.7.1의 버전이 마스터 노드의 버전과 상이하여 샤딩이 되지 않았다.</p><pre><code class="json">GET /_cluster/allocation/explain// 생략&quot;nodeuuid2&quot;: {            &quot;final_decision&quot;: &quot;NO&quot;            &quot;decisions&quot;: [                {                    &quot;decider&quot; : &quot;node_version&quot;,                    &quot;decision&quot; : &quot;NO&quot;,                    &quot;explanation&quot; : &quot;target node version [6.7.0] is older than source node version [6.7.1]&quot;                }            ],            &quot;weight&quot;: 1.3        }</code></pre><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><p>버전을 다시 바꾸어서 ES를 실행시키자, 별도의 액션없이 천천히 샤딩이 되면서 서비스가 정상화 되었다.<br>정상이 된 샤드는 allocation explain쿼리에 다음과 같이 응답한다.</p><pre><code class="json">GET /_cluster/allocation/explain{  &quot;error&quot;: {    &quot;root_cause&quot;: [      {        &quot;type&quot;: &quot;illegal_argument_exception&quot;,        &quot;reason&quot;: &quot;unable to find any unassigned shards to explain [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false]&quot;      }    ],    &quot;type&quot;: &quot;illegal_argument_exception&quot;,    &quot;reason&quot;: &quot;unable to find any unassigned shards to explain [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false]&quot;  },  &quot;status&quot;: 400}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;문제&quot;&gt;&lt;a href=&quot;#문제&quot; class=&quot;headerlink&quot; title=&quot;문제&quot;&gt;&lt;/a&gt;문제&lt;/h1&gt;&lt;p&gt;Elasticsearch 홈페이지에서 공식 docker 이미지를 받아 새로운 노드가 되는 서버를 구성했는데,&lt;br&gt;그새 버전이
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>테스트 자동화 - (1) Appium 서버 실행하기 (+안드로이드 테스트환경 세팅)</title>
    <link href="https://parkdoyeon.github.io/web/web-2019-06-12-appium/"/>
    <id>https://parkdoyeon.github.io/web/web-2019-06-12-appium/</id>
    <published>2019-06-12T01:29:19.000Z</published>
    <updated>2019-07-02T14:07:25.485Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Appium"><a href="#Appium" class="headerlink" title="Appium"></a>Appium</h1><p>Appium은 네이티브/하이브리드/웹앱 모바일 테스트 자동화를 위한 오픈소스로,<br>HTTP통신을 통해 타겟 디바이스에 요청을 보내는 서버 역할을 한다.<br>IOS 테스트시에는 애플에서 제공하는 XCUITest Driver를 통해 요청을 전달하고, Android 테스트시에는 구글에서 제공하는 UIAutomator2를 사용한다.</p><h1 id="설치"><a href="#설치" class="headerlink" title="설치"></a>설치</h1><p>appium은 npm을 통해 간단히 설치할 수 있다.<br>서비스가 돌아가기위한 환경세팅이 잘 되었는지 확인하기 위해 appium-doctor도 함께 설치하는 것이 좋다.</p><pre><code>&gt; npm install -g appium&gt; npm install -g appium-doctor</code></pre><h1 id="환경-세팅"><a href="#환경-세팅" class="headerlink" title="환경 세팅"></a>환경 세팅</h1><p>설치가 다  됐다면 명령창에서 appium-doctor을 실행해보자.</p><pre><code class="bash">&gt; appium-doctor</code></pre><p>아마 몇가지 변수들이 세팅이 안됐다는 에러가 나올 것이다.<br>(적어도 윈도우환경에서) appium을 실행하려면 다음과 같이 환경변수를 세팅해줘야한다.<br>환경 세팅과 관해서는 <a href="https://dejavuqa.tistory.com/222" rel="external nofollow noopener noreferrer" target="_blank">이 글</a>을 참고했다.<br>아래의 변수 세팅내용이 이해가 어려우면 링크를 타고 들어가 순서대로 세팅하면 된다.<br>간략하게 정리하면 다음과 같다.</p><h4 id="시스템-변수-Path에-추가해줘야-하는-내용"><a href="#시스템-변수-Path에-추가해줘야-하는-내용" class="headerlink" title="시스템 변수 Path에 추가해줘야 하는 내용"></a>시스템 변수 Path에 추가해줘야 하는 내용</h4><ul><li><code>%JAVA_HOME%\bin</code></li><li><code>%ANDROID_HOME%\emulator</code></li><li><code>%ANDROID_HOME%\tools</code></li><li><code>%ANDROID_HOME%\platform-tools</code></li></ul><p>변수가 잘 설정되었는지 커맨드창에서 확인하면 된다.</p><pre><code class="bash">&gt; set JAVA_HOME&gt; set ANDROID_HOME&gt; set Path</code></pre><p>혹시 내가 설정한 경로가 출력되지 않는다면 설정창을 확인버튼을 눌러서 잘 껐는지 확인하고,<br>그래도 안된다면 커맨드창을 종료했다 켜면 잘 나올 것이다.</p><h4 id="시스템-변수에-새로운-변수로-추가해줘야하는-변수"><a href="#시스템-변수에-새로운-변수로-추가해줘야하는-변수" class="headerlink" title="시스템 변수에 새로운 변수로 추가해줘야하는 변수"></a>시스템 변수에 새로운 변수로 추가해줘야하는 변수</h4><ul><li>JAVA_HOME <code>C:\Program Files\Java\jdk-9.0.1</code></li><li>ANDROID_HOME <code>C:\Users\doyeon\AppData\Local\Android\Sdk</code></li></ul><p>경로 끝에 세미콜론을 붙이면 appium이 인식하지 못하므로, 붙이지 않도록 주의한다.</p><p>각 경로는 서버의 PC환경마다 다를 수 있으므로 확인이 필요하다.<br><code>ANDROID_HOME</code>의 경우 안드로이드 스튜디오의 <code>Tools &gt; SDK Manager</code>에 들어가면 SDK 경로를 확인할 수 있다.<br><img src="/image/web/2019-06-12-appium-android.PNG" alt="android"></p><h4 id="Android-SDK-기본-세팅-설치"><a href="#Android-SDK-기본-세팅-설치" class="headerlink" title="Android SDK 기본 세팅 설치"></a>Android SDK 기본 세팅 설치</h4><p>환경변수가 세팅이 됐다면 안드로이드 테스트를 위해 몇가지 설치해야하는 툴들이 있다.<br>appium은 <code>ANDROID_HOME</code>변수를 통해 필요한 설치툴의 경로를 찾는다.<br>위 이미지 <code>Tools &gt; SDK Manager</code> 하단에 보면 SDK Tools탭이 있다.<br>탭을 누르고 들어가 아래의 내용을 체크하고 확인버튼을 누르면 설치를 시작한다.</p><ul><li>Android Emulator</li><li>Android SDK Platform-Tools</li><li>Android SDK Tools</li><li>Google Play Licensing Library</li><li>Google USB Driver</li></ul><h3 id="세팅-완료"><a href="#세팅-완료" class="headerlink" title="세팅 완료"></a>세팅 완료</h3><p>정상적으로 설치 되었다면 <code>appium</code>명령어를 입력하면 서비스가 실행될 것이다</p><pre><code class="bash">&gt; appium[Appium] Welcome to Appium v1.13.0[Appium] Appium REST http interface listener started on 0.0.0.0:4723</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Appium&quot;&gt;&lt;a href=&quot;#Appium&quot; class=&quot;headerlink&quot; title=&quot;Appium&quot;&gt;&lt;/a&gt;Appium&lt;/h1&gt;&lt;p&gt;Appium은 네이티브/하이브리드/웹앱 모바일 테스트 자동화를 위한 오픈소스로,&lt;br&gt;HTTP통신
      
    
    </summary>
    
      <category term="Web" scheme="https://parkdoyeon.github.io/web/"/>
    
    
      <category term="web" scheme="https://parkdoyeon.github.io/tags/web/"/>
    
      <category term="android" scheme="https://parkdoyeon.github.io/tags/android/"/>
    
      <category term="appium" scheme="https://parkdoyeon.github.io/tags/appium/"/>
    
      <category term="test-automation" scheme="https://parkdoyeon.github.io/tags/test-automation/"/>
    
  </entry>
  
  <entry>
    <title>hexo에 mathjax 적용하기</title>
    <link href="https://parkdoyeon.github.io/web/web-2019-06-07-mathjax/"/>
    <id>https://parkdoyeon.github.io/web/web-2019-06-07-mathjax/</id>
    <published>2019-06-07T08:02:33.000Z</published>
    <updated>2019-06-08T11:13:46.134Z</updated>
    
    <content type="html"><![CDATA[<p>머신러닝 공부를 하다보니 수식을 입력해야하는데, 처음에는 직접 cdn을 호출해서 적용했었다. 꽤 간단하게 되는 것 같아 별도로 수정을 안하다가 어느날 로그(\(logx\))입력시 브라켓({})에서 띄워쓰기를 안해주니 다음과 같이 렌더링 에러가 났다.</p><pre><code class="bash">Template render error: (unknown path) [Line 14, Column 244]  expected variable end    at Object._prettifyError (/Users/doyeon/Dev/blog/node_modules/nunjucks/src/lib.js:36:11)    at Template.render (/Users/doyeon/Dev/blog/node_modules/nunjucks/src/environment.js:542:21)    at Environment.renderString (/Users/doyeon/Dev/blog/node_modules/nunjucks/src/environment.js:380:17)    at Promise.fromCallback.cb (/Users/doyeon/Dev/blog/node_modules/hexo/lib/extend/tag.js:62:48)    at tryCatcher (/Users/doyeon/Dev/blog/node_modules/bluebird/js/release/util.js:16:23)# (후략)</code></pre><p>구글링 하다보니 띄워쓰기가 문제가 되는 경우가 있다고 해서 브라켓에 띄워쓰기를 넣었더니 에러가 사라졌다.<br>이참에 종종 인라인 수식에 적용이 안되는 경우까지 해결해보려고 정석대로 hexo에 mathjax를 적용하도록 하는 글을 찾아봤다.</p><p>정리가 잘 된 글이 있었지만 노드 모듈 스크립트를 직접 수정해야해서 git 저장소를 통해 여러 PC에서 포스트를 작성하는 내 입장에서는 번거로운 구석이 있었다. (node_module이 .gitignore에 있으므로)</p><p>그래서 소스수정이 없는 방식을 찾다가 <a href="https://linkinpark213.com/2018/04/24/mathjax/" rel="external nofollow noopener noreferrer" target="_blank">이 글</a>을 찾았다.<br>블로그 디렉토리에 hexo-math를 다운로드 받아 사용하는 글이다. 그런데 무엇이 잘못됐는지 이상하게</p><ol><li>_config내에 cdn호출 입력해도 페이지에 호출이 안되는데다,</li><li>mathjax를 _config파일 최상위에 정의하는게 deprecate가 되고 있었다.</li><li>게다가 함께 설치되는 hexo-inject 모듈이 더이상 업데이트가 되지 않는다는 안내가 나왔다.</li></ol><p>알고보니 인라인에 적용이 안되는 문제는</p><pre><code>$ 이렇게 $ 쓰던걸 \\( 이렇게 \\) 바꾸니까 해결이 됐다.</code></pre><p>정리하면,</p><ol><li>header영역에 cdn 호출 스크립트 직접 추가하고<pre><code class="sass">&lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</code></pre></li><li>수식입력하기만 바꾸는걸로.<pre><code>$$  수식 $$ # 단독입력\\( 수식 )\\ # 인라인 입력</code></pre></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;머신러닝 공부를 하다보니 수식을 입력해야하는데, 처음에는 직접 cdn을 호출해서 적용했었다. 꽤 간단하게 되는 것 같아 별도로 수정을 안하다가 어느날 로그(\(logx\))입력시 브라켓({})에서 띄워쓰기를 안해주니 다음과 같이 렌더링 에러가 났
      
    
    </summary>
    
      <category term="Web" scheme="https://parkdoyeon.github.io/web/"/>
    
    
      <category term="web" scheme="https://parkdoyeon.github.io/tags/web/"/>
    
      <category term="hexo" scheme="https://parkdoyeon.github.io/tags/hexo/"/>
    
      <category term="mathjax" scheme="https://parkdoyeon.github.io/tags/mathjax/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning From Scratch - 2. 신경망 학습</title>
    <link href="https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/"/>
    <id>https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/</id>
    <published>2019-06-02T05:20:01.000Z</published>
    <updated>2019-06-27T15:33:15.455Z</updated>
    
    <content type="html"><![CDATA[<h3 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h3><ul><li>‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 <strong>자동</strong>으로 획득하는 것을 뜻한다.</li><li>매개변수 최적값을 학습할 수 있도록 해주는 <strong>지표</strong>는 손실함수이다.<ul><li>왜 정확도가 아닌 손실함수인가?<ul><li>정확도를 지표료 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. (= 소숫점 단위로 표현되는 연속적인 수치값이 아닌 단절된 숫자값으로 표현되기가 쉽다.)</li></ul></li></ul></li><li>손실함수를 최대한 작게 만들어주도록 하는 기법중 하나로, 함수의 기울기를 활용하는 것이 ‘경사법’이다.</li><li>입력부터 출력까지 사람의 개입이 없다는 의미에서, 딥러닝을 종단간 기계학습(end-to-end learning)이라고 한다.</li><li>한 데이터셋에만 지나치게 최적화된 상태를 <strong>오버피팅</strong>이라고 한다.</li></ul><h3 id="1-손실함수"><a href="#1-손실함수" class="headerlink" title="1. 손실함수"></a>1. 손실함수</h3><h4 id="1-1-평균-제곱-오차"><a href="#1-1-평균-제곱-오차" class="headerlink" title="1.1 평균 제곱 오차"></a>1.1 평균 제곱 오차</h4><p>$$ E = { { 1\over2 } \sum_ { k } ( y_k-t_k)^2 } $$</p><ul><li>\(y_k\)는 신경망이 추정한 출력값, \(t_k\)는 실제 정답레이블 값(원-핫 인코딩), k는 차원의 수를 의미한다.</li><li>결과값으로 나타난 손실값의 합들이 높을수록 정답과 멀어지고, 적을수록 정답에 가깝다.</li></ul><h4 id="1-2-교차-엔트로피-오차"><a href="#1-2-교차-엔트로피-오차" class="headerlink" title="1.2 교차 엔트로피 오차"></a>1.2 교차 엔트로피 오차</h4><p>$$  E = - { \sum_ { k } t_k logy_k } $$</p><ul><li>여기서 \(logy\)는 자연로그 \(log_en\)를 취한다.</li><li>\(t_k\)는 원-핫 인코딩 값이므로 실질적으로 \(t_k\)가 1일때의 \(logy_k\)을 계산한 값, 즉 정답 추정값의 자연로그를 계산하는 식이 된다.<ul><li>여기서 정답과 거리가 먼 결과가 발생할수록(x가 1에 가까워질수록) 엔트로피 오차(loss)가 더 크게 발생한다.</li><li>\(log_ex=y\)의 그래프<br><img src="/image/ml/2019-06-02-deep2-1.png" alt="log_ex=y의 그래프"></li><li>가령 신경망 출력이 0.6일때 교차 엔트로피 오차가 \(-log0.6 = 0.51\)이라면, 0.1일때는 \(-log0.1=2.3\)이 된다.</li></ul></li></ul><h4 id="1-3-미니-배치-함수"><a href="#1-3-미니-배치-함수" class="headerlink" title="1.3 미니 배치 함수"></a>1.3 미니 배치 함수</h4><p>$$  E = - { 1 \over N } \sum { \sum_ { k } t_k logy_k } $$</p><ul><li>앞서서 구한 교차 엔트로피 오차를 모두 구해서 갯수만큼 나누면 평균 교차 엔트로피값을 구할 수 있다. 이렇게 하면 훈련 데이터 개수와 관계없이 통일된 지표를 구할 수 있다.</li><li>전체 데이터가 수천 수십만개가 되면 교차 엔트로피 값을 구하는것은 무리가 있으므로 데이터 일부를 추려서 근사치로 이용할 수 있다.</li><li>추려진 일부 데이터를 <strong>미니배치</strong>라고 한다.</li></ul><h3 id="2-수치미분"><a href="#2-수치미분" class="headerlink" title="2. 수치미분"></a>2. 수치미분</h3><h4 id="2-1-수치미분과-오차"><a href="#2-1-수치미분과-오차" class="headerlink" title="2.1 수치미분과 오차"></a>2.1 수치미분과 오차</h4><ul><li>미분방법에는 수치 미분과 해석적 미분이 있다.<ol><li>수치미분은 실제 변화량을 수치적으로 계산하는 것으로, 변화값인 h에 최대한 작은 값(보통 \(\lim_{h\to0}\)으로 표현된다.)을 대입하여 계산한다.</li><li>해석적 미분은 수식적으로 미분함수를 만들어 미분값을 찾는 것을 의미한다.</li></ol></li><li>수치미분을 코드로직에 적용할 때 h의 최솟값을 대입하다보면 아래와 같은 문제가 발생한다.<br>수치미분을 구하는 파이썬 함수를 예로들면,<pre><code class="python">  def numerical_diff(f, x):      h = 10e-50      return (f(x+h)+f(x)/h)</code></pre>  아래와 같이 소숫점 8자리 이하부터 생략해 최종 계산값에 오차가 발생한다.<pre><code class="bash">  &gt;&gt;&gt; np.float32(1e-50)  0.0</code></pre>  때문에 \(10^{-4}\)정도의 값을 사용할 것을 권장한다.</li><li>수치미분에서 발생하는 오차는 필연적이기 때문에, 변화량이 +h인 미분과 -h인 미분의 중앙값을 구하기도 한다.</li></ul><h4 id="2-2-편미분"><a href="#2-2-편미분" class="headerlink" title="2.2 편미분"></a>2.2 편미분</h4><ul><li>편미분은 변수가 2개 이상인 경우에 사용한다. 3차원으로 그래프가 그려지므로, 미분값을 구할때는 변수 하나에 초점을 맞추고 다른 변수는 값을 고정한다.</li><li>편미분한 기울기 값에 마이너스 부호를 붙이고 2차원 벡터로 표현하면 각 지점에서 낮아지는 방향을 가리킨다. </li><li>이말인 즉, <strong>기울기가 가리키는 곳은 각 장소의 함수에서 함수의 출력 값을 가장 크게 줄이는 방향</strong>이다.</li></ul><h4 id="2-3-경사법"><a href="#2-3-경사법" class="headerlink" title="2.3 경사법"></a>2.3 경사법</h4><ul><li>경사법은 경사 하강법이라고 한다. 손실함수가 최소가 되는 값을 찾기위해 기울기를 활용하는 방법이다.</li><li>기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지는 보장할 수 없다. 실제로 최솟값이 없는 경우가 대부분이다.</li><li>다만 그 방향으로 가야 줄일 수 있다는 사실은 확실하므로, 기울어진 방향으로 일정 거리만큼 이동해나가면서 줄이는게 경사법이라고 한다.</li><li>최솟값을 찾으면 경사 하강법, 최댓값을 찾으면 경사 상승법이다. 단순히 기울기에 마이너스를 붙이냐 아니냐의 차이이므로 방법과 내용의 실질적인 차이는 없다.</li></ul><h3 id="2-3-1-경사법의-수식"><a href="#2-3-1-경사법의-수식" class="headerlink" title="2.3.1 경사법의 수식"></a>2.3.1 경사법의 수식</h3><p>$$ x_0 = x_0 - \eta { \partial f \over \partial x_0 },  x_1 = x_1 - \eta { \partial f \over \partial x_1 } $$</p><ul><li><p>\( \eta \)(eta)기호는 갱신하는 양을 나타낸다. 보통 0.01이나 0.001 등 특정값으로 정해둔다. 신경망 학습에서는 <strong>학습률</strong>이라고 한다.</p></li><li><p>위의 식은 1회의 갱신이 일어나는 식이며, 만족스러운 값이 나타날때까지 갱신을 반복한다.</p><pre><code class="python">  # f: 최적화 함수  # init_x: 초기값  # learning_rate: 학습률  # step_num: 경사법에 따른 반복횟수   def gradient_descent (f, init_x, learning_rate=0.01, step_num=100):      x=init_x      for i in range(step_num):          grad = numerical_gradient(f, x)          x -= lr*grad      return x</code></pre></li><li><p>학습률과 같은 매개변수를 하이퍼파라미터라고 한다. 가중치/편향과 같은 신경망 매개변수와는 성질이 다른 매개변수이다.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;개요&quot;&gt;&lt;a href=&quot;#개요&quot; class=&quot;headerlink&quot; title=&quot;개요&quot;&gt;&lt;/a&gt;개요&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 &lt;strong&gt;자동&lt;/strong&gt;으로 획득하는 것을 뜻한
      
    
    </summary>
    
      <category term="ML" scheme="https://parkdoyeon.github.io/ml/"/>
    
    
      <category term="machine-learning" scheme="https://parkdoyeon.github.io/tags/machine-learning/"/>
    
      <category term="deep-learning" scheme="https://parkdoyeon.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch - unassigned shard 문제 해결 (1) shard가 너무 많을 때</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-05-31-es-shards/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-05-31-es-shards/</id>
    <published>2019-05-31T01:11:02.000Z</published>
    <updated>2019-06-27T15:33:15.453Z</updated>
    
    <content type="html"><![CDATA[<h3 id="문제상황"><a href="#문제상황" class="headerlink" title="문제상황"></a>문제상황</h3><p>ELK 스택을 개발하면서 운영 경험이 전무했던 나는 점진적으로 인덱스를 추가하고, 서비스에 지장이 있는 시점부터 확장을 할 계획이었다. 그리고 과거에 잠시 ES용으로 사용했던 서버 2대로 노드를 운영했다. 서버의 스펙은 아래와 같았다.</p><ul><li>RAM: <code>16G</code></li><li>CPU: <code>8</code></li><li>DISK: <code>/DATA 300G, /ROOT 100G</code></li></ul><p>그런데 어느순간부터 서비스 추가할때마다 ES가 죽거나, 안정적인 상태로 돌아오기까지 너무 오랜 시간(약 4시간 정도)이 소요됐다. </p><p>RAM이 문제였을까, CPU가 문제였을까(RAM이 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/hardware.html" rel="external nofollow noopener noreferrer" target="_blank">이상적인 권장 사양</a>이 아님은 확실했다). 표면적인 징후는 bulk insert 큐가 가득 차는 문제이지만, 이는 시간이 지나거나 초기에 insert하는 데이터를 조절하면 해소가 되는 문제였다. 진짜 문제는 shard 할당에 있었다. </p><h3 id="너무-많은-샤드"><a href="#너무-많은-샤드" class="headerlink" title="너무 많은 샤드?"></a>너무 많은 샤드?</h3><p>우선 ES에 찍힌 로그를 봤다. 샤드가 너무 많다는 메세지가 있었다.</p><pre><code>#! Deprecation: In a future major version, this request will fail because this action would add [9xx] total shards,but this cluster currently has [8xxx]/[2000] maximum shards open.Before upgrading, reduce the number of shards in your cluster or adjust the cluster setting [cluster.max_shards_per_node].</code></pre><p> ES는 워낙 버전 업이 잦은데다 위의 메세지는 deprecation 경고였기 때문에, 가볍게 여겼다. 하지만 아래의 또 다른 에러 메세지를 보고 shard 문제임을 알 수 있었다. 샤드의 할당과 라우팅이 잘 이뤄지지 않는다는 내용이다.</p><pre><code>[kr-service-2019.05.25], type [index_stats], id [AV9RswFhsIL8o1ZCN3Mi],message [UnavailableShardsException[[kr-service-2019.05.25][0] Primary shard is not active or isn&#39;t assigned to a known node. Timeout: [1m], request: org.elasticsearch.action.bulk.BulkShardRequest@4f100b34]]]</code></pre><p>ES 노드 1개의 최대 샤드의 갯수 기본 설정은 2000개이다. 노드당 샤드를 늘려주면 문제가 해결될까 해서 샤드갯수를 5000까지 늘렸다.</p><pre><code>PUT /_cluster/settings{    &quot;persistent&quot; : {        &quot;cluster.max_shards_per_nodes&quot; : 5000    }}</code></pre><p>메세지는 사라졌지만, unassigned 문제가 해소되진 않았고, ES에 할당된 메모리는 줄어들 생각을 하지 않고 80%이상으로 치고 올라왔다. 부랴부랴 ES 공식사이트에 있는 shard 관리에 대한 <a href="https://www.elastic.co/kr/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster" rel="external nofollow noopener noreferrer" target="_blank">문서</a>를 읽었다. 매우 중요한 팁들이 있었는대 아래와 같은 내용이었다.</p><blockquote><p>TIP: 작은 샤드는 작은 세그먼트를 만들며 부하를 증가시킵니다. 평균 샤드 크기를 최소한 수 GB와 수십 GB 사이를 유지하세요. 시간 기반 데이터를 사용한 과거 사례를 보면, 20GB ~ 40GB 정도의 사이즈가 적당합니다.<br><br><br>TIP: 각 샤드의 부하는 세그먼트 개수와 크기에 따라 결정됩니다. forcemerge 기능을 사용하여 작은 세그먼트를 큰 세그먼트로 병합시키세요. 이 작업은 이상적으로 인덱스에 더 이상 데이터가 입력되지 않을 때 실행되어야 합니다. 그리고 무척 부하가 큰 작업이니 피크 시간을 피하여 수행해야 하는 것을 명심하세요.<br><br><br>TIP: 하나의 노드에 저장할 수 있는 샤드의 개수는 가용한 힙의 크기와 비례하지만, Elasticsearch에서 그 크기를 제한하고 있지는 않습니다. 경험상 하나의 노드에 설정한 힙 1GB 당 20개 정도가 적당합니다. 따라서 30GB 힙을 가진 노드는 최대 600개 정도의 샤드를 가지는 것이 가능하지만, 이 보다는 적게 유지하는 것이 더 좋습니다. 일반적으로 이러한 구성은 클러스터를 건강하게 유지하는데 도움이 됩니다</p></blockquote><p>요약하면 샤드의 갯수와 힙의 크기는 비례하는데, 나는 힙과 사용하는 데이터 크기(한 인덱스당 1~2G정도 사용)에 비해 지나치게 많은 샤드 할당을 하고있었다. 애초에 왜 이런 문제가 생겼는가 보니, Logstash에서 인덱스 생성시 샤드갯수가 5개로 생성되고 있었다. 기본 설정으로. (맙소사)</p><h3 id="샤드-줄이기"><a href="#샤드-줄이기" class="headerlink" title="샤드 줄이기"></a>샤드 줄이기</h3><p>우선 생성된 샤드를 일괄로 삭제할수는 없으니, 신규 생성하는 인덱스부터 설정을 바꿔주기로 했다. 방법은 꽤 간단하다. _template 요청으로 인덱스 생성시 샤드 설정을 지정하면 된다.</p><pre><code class="curl">GET _template/kr_shards_control{  &quot;index_patterns&quot;: &quot;kr-*&quot;,  &quot;settings&quot;: {    &quot;number_of_shards&quot;:   2  }}</code></pre><p>추가적으로 문제가 있던 시점에 추가했던 인덱스를 전부 삭제하고, 필요가 없는 오래된 인덱스도 일부 삭제했다. 그리고 데이터를 다시 받아 샤드 2개짜리로 생성했다. 30분 정도 지나니 메모리 수치도 점차 가라앉고, CPU도 안정되는 것을 확인할 수 있었다. 그리고 퇴근을 했다. 하지만 <a href="/elk/elk-2019-06-18-es-version">다른 문제</a>가 있었는데…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;문제상황&quot;&gt;&lt;a href=&quot;#문제상황&quot; class=&quot;headerlink&quot; title=&quot;문제상황&quot;&gt;&lt;/a&gt;문제상황&lt;/h3&gt;&lt;p&gt;ELK 스택을 개발하면서 운영 경험이 전무했던 나는 점진적으로 인덱스를 추가하고, 서비스에 지장이 있는 시점부터
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="shards" scheme="https://parkdoyeon.github.io/tags/shards/"/>
    
      <category term="template" scheme="https://parkdoyeon.github.io/tags/template/"/>
    
  </entry>
  
  <entry>
    <title>도커/도커 컴포즈 설치하고 서비스 시작하기</title>
    <link href="https://parkdoyeon.github.io/docker/docker-2019-05-30-docker-install/"/>
    <id>https://parkdoyeon.github.io/docker/docker-2019-05-30-docker-install/</id>
    <published>2019-05-30T06:25:27.000Z</published>
    <updated>2019-06-08T02:58:52.616Z</updated>
    
    <content type="html"><![CDATA[<h2 id="도커-설치하기"><a href="#도커-설치하기" class="headerlink" title="도커 설치하기"></a>도커 설치하기</h2><ul><li>[<a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#set-up-the-repository" rel="external nofollow noopener noreferrer" target="_blank">Docker 설치 가이드</a>] 최초 설치시 반드시 저장소 등록(SET UP THE REPOSITORY)부터 할 것!</li><li>설치 후 자동시작이지만 혹시 서비스가 꺼져있다면 배시 통해서 도커 서비스 시작<pre><code class="bash">service docker start</code></pre></li></ul><h2 id="도커-서비스가-시작이-안되면-네트워크-확률이-높다"><a href="#도커-서비스가-시작이-안되면-네트워크-확률이-높다" class="headerlink" title="도커 서비스가 시작이 안되면 ? 네트워크 확률이 높다"></a>도커 서비스가 시작이 안되면 ? 네트워크 확률이 높다</h2><ol><li>로그보기.<pre><code class="bash">journalctl -xe</code></pre></li><li>출력되는 로그 자세히 보면 아래와 같은 내용이 있다.<pre><code class="bash">Error starting daemon: Error initionalizing network controller</code></pre></li><li>이럴땐 직접 ip 지정<pre><code class="bash">root$ ip link add name docker0 type bridgeroot$ ip addr add dev docker0 172.17.0.1/16root$ service docker start</code></pre></li></ol><h2 id="Docker-Compose-설치하기"><a href="#Docker-Compose-설치하기" class="headerlink" title="Docker-Compose 설치하기"></a>Docker-Compose 설치하기</h2><ul><li><a href="https://docs.docker.com/compose/install/#install-compose" rel="external nofollow noopener noreferrer" target="_blank">DockerCompose 설치 가이드</a></li><li>서비스 시작하기 전에 엉뚱한 곳에 실행 권한을 주진 않았나 확인하자.</li><li>apt install docker-compose명령어로 설치하면 구버전(2.2)이 설치된다. 최신버전인 3.2로 설치하기위해선 설치가이드 따르는 것이 좋다.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;도커-설치하기&quot;&gt;&lt;a href=&quot;#도커-설치하기&quot; class=&quot;headerlink&quot; title=&quot;도커 설치하기&quot;&gt;&lt;/a&gt;도커 설치하기&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;[&lt;a href=&quot;https://docs.docker.com/install/li
      
    
    </summary>
    
      <category term="Docker" scheme="https://parkdoyeon.github.io/docker/"/>
    
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="install" scheme="https://parkdoyeon.github.io/tags/install/"/>
    
  </entry>
  
  <entry>
    <title>ElastAlert - 유용한 규칙 종류</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-05-29-ea-elastalert/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-05-29-ea-elastalert/</id>
    <published>2019-05-29T11:07:16.000Z</published>
    <updated>2019-06-27T15:33:15.453Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/Yelp/elastalert" target="_blank" rel="noopener">ElastAlert</a>은 조건에 따라 Elasticsearch에서 발생하는 문서에 대한 알럿을 보내주는 오픈소스이다. 각각의 규칙(Rule) yml파일을 생성하면 지정한 Rule 디렉토리에 있는 설정대로 ES에 쿼리하는 구조로,<br>직접 파일을 생성해서 관리해줄수도 있고, Kibana에 ElastAlert 플러그인을 추가해서 규칙 관리를 할수도 있다. </p><p>규칙은 다양한 타입이 있는데, ELK 로그 스택을 운영하면서 가장 많이 활용했던 Rule타입은 아래와 같다. 전반적인 내용은 <a href="https://elastalert.readthedocs.io/en/latest/ruletypes.html" rel="external nofollow noopener noreferrer" target="_blank">공식문서</a>를 참조하면된다.</p><h2 id="cardinality-특정-필드의-값의-종류를-제한하고싶을때"><a href="#cardinality-특정-필드의-값의-종류를-제한하고싶을때" class="headerlink" title="cardinality: 특정 필드의 값의 종류를 제한하고싶을때"></a>cardinality: 특정 필드의 값의 종류를 제한하고싶을때</h2><pre><code class="yml">name: gender alerttype: cardinalityindex: customer-%Y.%m.%duse_strftime_index: truecardinality_field: &quot;gender&quot; # 제약을 두고싶은 필드# 종류의 갯수(반대로 최소값을 설정하고싶으면 min_cardinality으로 세팅)max_cardinality: 2  alert_subject: &quot;남/녀 외의 또 다른 필드값 발생!&quot;</code></pre><h2 id="metric-aggregation-특정-값의-발생-빈도를-카운팅하고싶을-때"><a href="#metric-aggregation-특정-값의-발생-빈도를-카운팅하고싶을-때" class="headerlink" title="metric_aggregation: 특정 값의 발생 빈도를 카운팅하고싶을 때"></a>metric_aggregation: 특정 값의 발생 빈도를 카운팅하고싶을 때</h2><pre><code class="yml">name: sql datatype: metric_aggregationindex: inserted-sql-data-%Y.%m.%duse_strftime_index: truemetric_agg_key: &quot;pk-field&quot; # 카운팅 하고싶은 대상 필드의 이름metric_agg_type: value_count # value가 되는 값의 count를 한다는 것을 의미, 숫자크기와 같은 다른 방식의 카운팅방법 지정도 가능하다.query_key: &quot;pk-field.keyword&quot; # 대상으로 할 value에 대한 쿼리를 넣어주면 된다 max_threshold: 1 # 내 경우 중복이 발생하면 무조건 알럿이 와야하므로 최대 갯수는 1개.doc_type: docalert_subject: &quot;pk-field에 중복된 값이 있습니다.&quot;</code></pre><h2 id="any-어떤-문서든-발생하면-바로"><a href="#any-어떤-문서든-발생하면-바로" class="headerlink" title="any: 어떤 문서든 발생하면 바로!"></a>any: 어떤 문서든 발생하면 바로!</h2><pre><code class="yml">name: Fatal Errortype: anyindex: fatal-log-%Y.%m.%duse_strftime_index: truefilter:- query:    query_string:      query: &quot;log.level: fatal&quot;alert_subject: &quot;fatal 에러가 발생했습니다.&quot;</code></pre><h2 id="frequency-특정-갯수-이상의-문서가-발생했을때"><a href="#frequency-특정-갯수-이상의-문서가-발생했을때" class="headerlink" title="frequency: 특정 갯수 이상의 문서가 발생했을때"></a>frequency: 특정 갯수 이상의 문서가 발생했을때</h2><pre><code class="yml">name: Web Error Alerttype: frequencyindex: web-log-%Y.%m.%duse_strftime_index: true# 10분간 20번의 에러 로그가 발생하면 알럿num_events: 20timeframe:  minutes: 10filter:- query:    query_string:      query: &quot;fields.level: error&quot;alert_subject: &quot;지속적인 에러가 발생했습니다.&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://github.com/Yelp/elastalert&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ElastAlert&lt;/a&gt;은 조건에 따라 Elasticsearch에서 발생하는 문서에 대한 알럿을 보내주는 오
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="elk" scheme="https://parkdoyeon.github.io/tags/elk/"/>
    
      <category term="elastalert" scheme="https://parkdoyeon.github.io/tags/elastalert/"/>
    
  </entry>
  
  <entry>
    <title>셀레니움과 pytest로 브라우저 테스트 하기</title>
    <link href="https://parkdoyeon.github.io/python/python-2019-05-28-selenium-to-pytest/"/>
    <id>https://parkdoyeon.github.io/python/python-2019-05-28-selenium-to-pytest/</id>
    <published>2019-05-28T06:55:53.000Z</published>
    <updated>2019-06-10T14:18:16.119Z</updated>
    
    <content type="html"><![CDATA[<h1 id="디렉토리-구조"><a href="#디렉토리-구조" class="headerlink" title="디렉토리 구조"></a>디렉토리 구조</h1><p>우선 pytest 샘플 프로젝트의 이렇다. 각각의 파일의 특징들은 아래와 같다.</p><pre><code class="bash">D:.│  conftest.py # 파이테스트에서 공통적으로 사용할 객체들을 구현한 모듈│  inspection_test.py # 브라우저를 테스트하는 클래스/함수가 구현된 모듈│  requirements.txt # pip으로 설치된 패키지 리스트│├─allure-results├─bin│      chromedriver72.exe│      IEDriverServer.exe├─venv└─__pycache__</code></pre><h1 id="conftest-py-공통-객체-설정하기"><a href="#conftest-py-공통-객체-설정하기" class="headerlink" title="conftest.py: 공통 객체 설정하기"></a>conftest.py: 공통 객체 설정하기</h1><p>pytest는 conftest.py라는 이름을 가진 스크립트에서 터미널 실행시 지정할 옵션값을 설정하거나,<br>각 테스트 함수에서 공통으로 사용하는 오브젝트(가령 셀레니움에서 사용할 브라우저 엔진같은)를 생성할 수 있다.</p><pre><code class="python">import pytestimport allure# 터미널 옵션 설정def pytest_addoption(parser):    # 아래에서 params 값에 세팅해줄 예정이니 패스    # parser.addoption(&quot;--driver&quot;, action=&quot;store&quot;, default=&quot;chrome&quot;, help=&quot;Type in browser type&quot;)    parser.addoption(&quot;--url&quot;, action=&quot;store&quot;, default=&quot;http://test.website.co.kr&quot;, help=&quot;url&quot;)# @pytest.fixture 데코레이터를 통해 리스트 형식인 파라미터를 넘기면,# params값이 루프를 돌면서 인자 순서대로 함수가 여러번 호출된다.@pytest.fixture(params=[&quot;chrome&quot;, &quot;ie&quot;], scope=&quot;class&quot;)def driver_get(request):    from selenium import webdriver    if request.param == &quot;chrome&quot;:        web_driver = webdriver.Chrome(&quot;bin/chromedriver72.exe&quot;)    if request.param == &quot;ie&quot;:        web_driver = webdriver.Ie(&quot;bin/IEDriverServer.exe&quot;)    request.cls.driver = web_driver    yield # yield 예약어를 통해 web_driver사용을 일시적으로 브라우저 엔진을 반환한다.</code></pre><h1 id="inspection-test-py-테스트-함수를-만드는-클래스-모듈"><a href="#inspection-test-py-테스트-함수를-만드는-클래스-모듈" class="headerlink" title="inspection_test.py: 테스트 함수를 만드는 클래스 모듈"></a>inspection_test.py: 테스트 함수를 만드는 클래스 모듈</h1><p>pytest를 실행하면 conftest.py에서 설정을 읽은 후 test가 접두어로 붙은 함수를 차례대로 호출한다.<br>이때, 호출 데코레이터에 파라미터를 지정해놓으면, 앞에서 설명한 conftest.py의 fixture 파라미터 처럼 값을 순차적으로 순회하면서 함수를 여러번 실행시킨다.</p><pre><code class="python">import pytestimport seleniumimport allurefrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.common.by import Byfrom selenium.common import exceptions as eximport dao@pytest.mark.usefixtures(&quot;driver_get&quot;)class TestInspection(object):    def get_targets():        # 타겟에 해당하는 튜플값을 반환하는 함수        # 데코레이터에서 직접 호출해도 된다.        return targets    @pytest.mark.parametrize(&quot;url, title&quot;, get_targets())    def test_search_inspection(self, url, title):        wait = WebDriverWait(self.driver, 3)        self.driver.get(url)        # 해당 ID값을 가진 태그가 화면에 등장하지 않으면 pytest의 결과를 통해 확인할 익셉션을 발생시킨다        with pytest.raises(ex.TimeoutException):            wait.until(EC.visibility_of_element_located((By.ID, &quot;alertSiteInspection&quot;)))        # allure report에 화면 스크린샷을 남긴다.        screenshot = &quot;data/&quot;+title+&quot;.png&quot;        self.driver.save_screenshot(screenshot)        allure.attach.file(screenshot, title+&quot;.png&quot;, attachment_type=allure.attachment_type.PNG)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;디렉토리-구조&quot;&gt;&lt;a href=&quot;#디렉토리-구조&quot; class=&quot;headerlink&quot; title=&quot;디렉토리 구조&quot;&gt;&lt;/a&gt;디렉토리 구조&lt;/h1&gt;&lt;p&gt;우선 pytest 샘플 프로젝트의 이렇다. 각각의 파일의 특징들은 아래와 같다.&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="Python" scheme="https://parkdoyeon.github.io/python/"/>
    
    
      <category term="python" scheme="https://parkdoyeon.github.io/tags/python/"/>
    
      <category term="selenium" scheme="https://parkdoyeon.github.io/tags/selenium/"/>
    
      <category term="pytest" scheme="https://parkdoyeon.github.io/tags/pytest/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins에 Python 환경세팅하고 Allure Report 연동하기</title>
    <link href="https://parkdoyeon.github.io/python/python-2019-05-28-jekins-to-pytest/"/>
    <id>https://parkdoyeon.github.io/python/python-2019-05-28-jekins-to-pytest/</id>
    <published>2019-05-28T06:17:02.000Z</published>
    <updated>2019-06-27T15:33:15.456Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Jekins에-파이썬-세팅하기"><a href="#Jekins에-파이썬-세팅하기" class="headerlink" title="Jekins에 파이썬 세팅하기"></a>Jekins에 파이썬 세팅하기</h1><ol><li>System Configuration &gt; Global Properties &gt; Environment Variables 체크<ul><li>이름: <code>PYTHON_PATH</code></li><li>값: <code>C:\Python\Python36;C:\Python\Python36\Scripts;</code> (젠킨스가 돌아가는 호스트 환경변수에 세팅된 파이썬 경로 입력)</li></ul></li><li>프로젝트 생성 &gt; 구성 &gt; General 탭 &gt; Build &gt; Add build step<ul><li>윈도우라면 Execute Windows Batch Command 선택하고 아래의 스크립트 추가</li><li>패키지 변경감지를 위해 파이썬 가상환경을 세팅하고 pip install 세팅<pre><code class="bash">SET PATH=%PATH%,%PYTHON_PATH%virtualenv venvcall venv/Scripts/activate.batpip install -r requirements.txtpy.test --alluredir=./allure-results # pytest의 allure report 결과 생성을 위한 디렉토리 설정deactivate</code></pre></li></ul></li></ol><h1 id="Jenkins에-Allure-Report-세팅"><a href="#Jenkins에-Allure-Report-세팅" class="headerlink" title="Jenkins에 Allure Report 세팅"></a>Jenkins에 Allure Report 세팅</h1><ol><li>플러그인 관리 &gt; 설치가능탭 &gt; Allure Jenkins Plugin 설치</li><li>프로젝트 생성 &gt; 구성 &gt; General 탭 &gt; Build &gt; 빌드 후 조치 &gt; 빌드 후 조치 추가<ul><li>Allure Report 선택 후, 위의 py.test에 파라미터로 넘긴 allure-results path를 넣어준다.<br><img src="/image/python/2019-05-28-jekins-to-pytest-1.PNG" alt="jenkins"></li></ul></li></ol><h1 id="Jenkins-빌드-실행하기"><a href="#Jenkins-빌드-실행하기" class="headerlink" title="Jenkins 빌드 실행하기"></a>Jenkins 빌드 실행하기</h1><p>빌드를 실행하면 대시보드에 다음과 같은 그래프가 생성된다. 그래프에는 테스트 성공케이스와 실패 케이스가 표시되어있다. 빌드 히스토리에는 케이스별 Allure-Report를 조회할 수 있는 아이콘이 생긴다.</p><p><img src="/image/python/2019-05-28-jekins-to-pytest-3.PNG" alt="jenkins"></p><h1 id="Allure-Report"><a href="#Allure-Report" class="headerlink" title="Allure Report"></a>Allure Report</h1><p>Allure Report 페이지에 들어가면 더 자세한 테스트 현황 그래프가 조회된다. Suites에 들어가면 케이스별 테스트 정보가 확인된다.</p><p>작성했던 테스트 코드 내에서 저장한 스크린샷도 테스트 함수 단위로 함께 첨부된 것을 볼 수 있다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Jekins에-파이썬-세팅하기&quot;&gt;&lt;a href=&quot;#Jekins에-파이썬-세팅하기&quot; class=&quot;headerlink&quot; title=&quot;Jekins에 파이썬 세팅하기&quot;&gt;&lt;/a&gt;Jekins에 파이썬 세팅하기&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;System C
      
    
    </summary>
    
      <category term="Python" scheme="https://parkdoyeon.github.io/python/"/>
    
    
      <category term="python" scheme="https://parkdoyeon.github.io/tags/python/"/>
    
      <category term="jenkins" scheme="https://parkdoyeon.github.io/tags/jenkins/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning From Scratch - 1. 퍼셉트론과 신경망</title>
    <link href="https://parkdoyeon.github.io/ml/ml-2019-05-27-deep/"/>
    <id>https://parkdoyeon.github.io/ml/ml-2019-05-27-deep/</id>
    <published>2019-05-27T10:38:00.000Z</published>
    <updated>2019-06-08T02:58:52.619Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-퍼셉트론"><a href="#1-퍼셉트론" class="headerlink" title="1. 퍼셉트론"></a>1. 퍼셉트론</h2><ul><li>뉴런에서 보내온 신호 총합이 정해진 한계(임계값)를 넘어서면 1, 아니면 0을 출력하는게 기본 원리.</li><li>신호는 가중치값 \(w\)와 곱한다.<ul><li>전류에서 말하는 저항을 생각하면 된다.</li><li>가중치가 높으면 신호가 크고, 가중치가 낮으면 신호가 낮다.</li></ul></li><li>활성화를 조정하는 상수 편향값 \(b\)를 더한다.</li><li>한계: AND, NAND(Not And: And의 반대 진리표), OR의 연산 구현이 가능하지만, XOR 게이트는 구현할 수 없다.</li></ul><h2 id="2-다층-퍼셉트론"><a href="#2-다층-퍼셉트론" class="headerlink" title="2. 다층 퍼셉트론"></a>2. 다층 퍼셉트론</h2><ul><li>선형구조인 퍼셉트론의 대안으로, 다층적으로 구현하는 퍼셉트론을 말한다.</li><li>다층 퍼셉트론의 NAND 연산만으로 컴퓨터를 구현할 수 있다.</li></ul><h2 id="3-신경망"><a href="#3-신경망" class="headerlink" title="3. 신경망"></a>3. 신경망</h2><ul><li>입력층, 은닉층, 출력층으로 구성되어있다.</li><li>두개의 신호 \(w_1\), \(w_2\)와 편향값 b가 있다고 가정할때, 다음과 같이 표현할 수 있다.<br>$$ y= h(b+w_1x_1+w_2x_2) $$</li><li>여기서 출력값 y를 도출하는 h(a)로 표현되는 함수는 활성화 함수라고 한다.</li></ul><h4 id="3-1-활성화-함수"><a href="#3-1-활성화-함수" class="headerlink" title="3.1 활성화 함수"></a>3.1 활성화 함수</h4><ul><li>활성화 함수는 신호의 총합을 출력의 신호로 변환하는 함수를 말한다.</li><li>신경망은 활성화 함수를 통해 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다.</li><li>책에서는 활성화 함수로 세 가지를 소개한다.<ol><li>계단함수<ul><li>입력이 0을 넘으면 1을, 그 외에는 0을 출력하는 함수이다.</li></ul></li><li>시그모이드 함수<ul><li>시그모이드 함수는 아래의 공식을 나타내며, e는 자연상수이다.<br>$$ h(x)= {1 \over 1+exp(-x)}$$<br>$$  exp(-x) = e^{-x}, e=2.7182… $$</li></ul></li><li>ReLU 함수<ul><li>입력이 0을 넘으면 그 입력을 그대로 출력하고, 0이하면 0을 출력하는 함수이다.</li></ul></li></ol></li><li>세 함수는 공통적으로 비선형 함수이고, 신경망에서는 활성화 함수로 비선형 함수를 사용해야한다<ul><li>선형함수를 이용하면 미분값이 값이 상수가 되며, 변화량이 상수면 신경망 층을 깊게하는 의미가 없어지기 때문이다.</li></ul></li></ul><h4 id="3-2-출력층-설계하기"><a href="#3-2-출력층-설계하기" class="headerlink" title="3.2 출력층 설계하기"></a>3.2 출력층 설계하기</h4><ul><li>기계학습은 분석(classification, 입력데이터를 구분), 회귀(regression, 입력데이터에서 연속적인 수치 예측)따라 활성화 함수를 달리쓴다.</li><li>두가지를 소개한다.<ol><li>항등함수<ul><li>회귀에서 주로 사용한다. 입력을 그대로 출력함.</li></ul></li><li>소프트맥스<ul><li>분류에서 주로 사용한다.</li><li>분자는 입력신호의 지수함수, 분모는 n개의 모든 입력신호의 지수함수의 합으로 구성된다<br> $$  y_k = {exp(a_k) \over \sum_ {i=0}^n exp(a_i)} $$<ul><li>분모의 값을 보면 모든 출력층의 뉴런이 모든 신호로부터 영향을 받는 것을 알 수 있다.</li><li>소프트 맥스 함수는 코드 구현시 지수값으로 인한 오버플로 문제가 있다. 이를 개선하기 위해 입력신호중 최대값을 뺀다.</li><li>아래의 식을 보면 어떤값을 더하거나 뺴도 결과값은 동일하다는 것을 보여준다.<br>$$  y_k = {exp(a_k) \over \sum_ {i=0}^n exp(a_i)} = {Cexp(a_k) \over C\sum_ {i=0}^n exp(a_i)}  $$<br>\(exp(n)\)는 지수함수이므로 C를 지수식에 밑이 e인 자연로그($log_e$)으로 취하면 덧셈식에 넣을 수 있다.<br>$$  = {exp(a_k+logC) \over \sum_ {i=0}^n exp(a_i+logC)} = {exp(a_k+C’) \over \sum_ {i=0}^n exp(a_i+C’)}$$</li></ul></li><li>소프트 맥스 함수의 출력은 0부터 1사이의 실수이며, 그렇기 때문에 출력을 확률로 해석할 수 있다.</li><li>\(y=exp(x)\)형식의 단조 증가함수이므로 원소간의 대소관계가 바뀌지는 않는다.</li><li>그렇기 떄문에 지수함수 계산에 드는 자원 낭비를 줄이기 위해 현업에서는 출력층의 소프트맥스 함수를 생략하기도 한다.</li></ul></li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-퍼셉트론&quot;&gt;&lt;a href=&quot;#1-퍼셉트론&quot; class=&quot;headerlink&quot; title=&quot;1. 퍼셉트론&quot;&gt;&lt;/a&gt;1. 퍼셉트론&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;뉴런에서 보내온 신호 총합이 정해진 한계(임계값)를 넘어서면 1, 아니면 0을 출력
      
    
    </summary>
    
      <category term="ML" scheme="https://parkdoyeon.github.io/ml/"/>
    
    
      <category term="machine-learning" scheme="https://parkdoyeon.github.io/tags/machine-learning/"/>
    
      <category term="deep-learning" scheme="https://parkdoyeon.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>ssms 사용할때 자주쓰는 명령어 정리</title>
    <link href="https://parkdoyeon.github.io/sql/sql-2019-05-27-ssms/"/>
    <id>https://parkdoyeon.github.io/sql/sql-2019-05-27-ssms/</id>
    <published>2019-05-27T08:36:00.000Z</published>
    <updated>2019-06-08T18:03:26.928Z</updated>
    
    <content type="html"><![CDATA[<p>SP 내용 보기</p><pre><code class="sql">sp_helptext &#39;[sp 이름]&#39;</code></pre><p>특정 구문이 포함되어있는 SP 찾기 (특정 테이블이나 컬럼을 사용하는 SP를 찾을때 유용하다)</p><pre><code class="sql">select * from sys.procedures p join sys.syscomments s on p.object_id = s.id where text like &#39;%[문자열]%&#39;;</code></pre><p>프로파일러 잡을때 DB ID 확인이 필요한경우</p><pre><code class="sql">select db_id(&#39;[db 이름]&#39;)</code></pre><p>도구 &gt; 옵션 &gt; 키보드 &gt; 쿼리 바로가기에서 아래처럼 키보드 단축키로 설정하고 사용하면 좋다.<br><img src="/image/sql/2019-05-27-ssms-1.png" alt="옵션"></p><ul><li>sp_lock : sp들의 점유상태를 보고싶을 때</li><li>sp_who : DB 로그인 정보와 호스트 확인</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SP 내용 보기&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;sp_helptext &amp;#39;[sp 이름]&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;특정 구문이 포함되어있는 SP 찾기 (특정 테이블이나 컬럼을 사용하는 SP를 찾을때 유용하다)&lt;/p
      
    
    </summary>
    
      <category term="SQL" scheme="https://parkdoyeon.github.io/sql/"/>
    
    
      <category term="mssql" scheme="https://parkdoyeon.github.io/tags/mssql/"/>
    
      <category term="insert" scheme="https://parkdoyeon.github.io/tags/insert/"/>
    
  </entry>
  
  <entry>
    <title>Hyper-V - 네트워크 환경세팅하기</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-04-29-hyperv/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-04-29-hyperv/</id>
    <published>2019-04-29T07:47:00.000Z</published>
    <updated>2019-07-13T09:32:43.641Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>네트워크를 설정할 가상컴퓨터를 누르고 오른쪽 작업란에 가상 스위치 관리자버튼 클릭</p></li><li><p>외부/내부/개인 중에 ‘내부’로 두가지 생성</p></li></ol><ul><li>외부: 호스트PC와 동위선상에서 네트워킹</li><li>내부: 호스트PC 네트워크를 타고 분기</li><li>외부/내부 두가지 방법으로 설정 다 가능하다. 다만 사내망 정책에 따라 외부로 설정하면 간혹 안되는 경우가 있으니 안전하게 내부로 설정하자</li></ul><ol start="3"><li><p>여러개의 Hyper V 가상 PC가 있다면 ‘내부용 스위치’로 외부통신을 위한 공유네트워크 카드 하나, 호스트통신 전용으로 하나 해서 스위치 두개를 만든다.</p><pre><code class="bash">sudo vi /etc/network/interfaces</code></pre><p> <img src="/image/dev-env/2019-04-29-hyperv1.jpeg" alt="설정 화면"></p></li><li><p>제어판&gt;네트워크 및 인터넷&gt;네트워크 연결에 들어가서 이더넷(호스트PC의 네트워크)의 속성&gt;공유 클릭</p></li><li><p>다른네트워크 사용자가 연결할수 있도록 허용체크, 홈네트워킹으로 “공유네트워크”를 설정해준다.</p><p> <img src="/image/dev-env/2019-04-29-hyperv2.png" alt="설정 화면2"></p></li><li><p>가상머신의 터미널에서 ifconfig를 입력하면 eith0(공유네트워크)는 DHCP를 통해 자동으로 IP가 생성되는 한편, eith1은 아직 IP를 할당받지 못한 상태</p><p> <img src="/image/dev-env/2019-04-29-hyperv3.jpeg" alt="IP Table"></p></li><li><p>아래의 명령어로 네트워크 설정 파일에 eth1의 고정ip를 다음과 같이 입력해준다.</p><pre><code class="bash">sudo vi /etc/network/interfaces</code></pre><p><img src="/image/dev-env/2019-04-29-hyperv4.png" alt="IP Table2"></p></li><li><p>네트워크 재시작 하면 끝~</p><pre><code class="bash">sudo systemctl restart networking.service</code></pre></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;네트워크를 설정할 가상컴퓨터를 누르고 오른쪽 작업란에 가상 스위치 관리자버튼 클릭&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;외부/내부/개인 중에 ‘내부’로 두가지 생성&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;외부: 호스트PC와 동위선상
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="network" scheme="https://parkdoyeon.github.io/tags/network/"/>
    
      <category term="hyper-v" scheme="https://parkdoyeon.github.io/tags/hyper-v/"/>
    
  </entry>
  
  <entry>
    <title>Python 독립실행환경 virtualenv 만들기</title>
    <link href="https://parkdoyeon.github.io/python/python-2019-04-18-python-venv/"/>
    <id>https://parkdoyeon.github.io/python/python-2019-04-18-python-venv/</id>
    <published>2019-04-18T09:32:00.000Z</published>
    <updated>2019-06-27T15:33:15.456Z</updated>
    
    <content type="html"><![CDATA[<p>virtaulenv를 통해 활상화된 가상환경 아래에서 개발하면,<br>파이썬 실행환경을 독립적으로 관리할 수 있는 것은 물론이고, 모듈관리를 체계적으로 할 수 있다.</p><p>pip 인스톨을 통해 virtualenv를 설치하고,<br>해당 프로젝트 경로에서 virtualenv 명령어를 통해 가상환경 이름을 명명하면<br>해당 디렉토리에 가상환경 디렉토리가 생성된다.</p><pre><code class="bash">pip3 install virtualenvcd [프로젝트 폴더]virtualenv venv</code></pre><h1 id="가상환경-활성화하기"><a href="#가상환경-활성화하기" class="headerlink" title="가상환경 활성화하기"></a>가상환경 활성화하기</h1><p>윈도우와 리눅스 활성화 방식이 조금씩 다르다. 위에가 윈도우고 아래가 리눅스 실행 명령어이다. </p><pre><code class="bash">venv/scripts/activatesource venv/bin/activate</code></pre><h1 id="비활성화-하기"><a href="#비활성화-하기" class="headerlink" title="비활성화 하기"></a>비활성화 하기</h1><pre><code class="bash">deactivate</code></pre><h1 id="패키지-정리-파일-만들기"><a href="#패키지-정리-파일-만들기" class="headerlink" title="패키지 정리 파일 만들기"></a>패키지 정리 파일 만들기</h1><pre><code class="bash">pip freeze &gt; requirement.txt</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;virtaulenv를 통해 활상화된 가상환경 아래에서 개발하면,&lt;br&gt;파이썬 실행환경을 독립적으로 관리할 수 있는 것은 물론이고, 모듈관리를 체계적으로 할 수 있다.&lt;/p&gt;
&lt;p&gt;pip 인스톨을 통해 virtualenv를 설치하고,&lt;br&gt;해당 프
      
    
    </summary>
    
      <category term="Python" scheme="https://parkdoyeon.github.io/python/"/>
    
    
      <category term="python" scheme="https://parkdoyeon.github.io/tags/python/"/>
    
      <category term="venv" scheme="https://parkdoyeon.github.io/tags/venv/"/>
    
      <category term="pip" scheme="https://parkdoyeon.github.io/tags/pip/"/>
    
  </entry>
  
  <entry>
    <title>Git - 실수로 용량이 큰 파일을 커밋했을 때</title>
    <link href="https://parkdoyeon.github.io/dev-env/dev-env-2019-04-07-git-large-file/"/>
    <id>https://parkdoyeon.github.io/dev-env/dev-env-2019-04-07-git-large-file/</id>
    <published>2019-04-07T10:14:00.000Z</published>
    <updated>2019-06-08T02:58:52.615Z</updated>
    
    <content type="html"><![CDATA[<p>회사에서 gitlab을 쓰면서 쾌적한 git life를 즐기다가 github에서는 100MB이상의 파일이 푸시가 안된다는 것을 알았다.<br>R 스터디 할때 써놓은 코드를 기록하려고 데이터와 함께 커밋을 해버렸는데, 커밋때 경고가 한번 떴(던거같은데)다가 푸시할때도 아래와 같은 에러를 뱉으며 push fail이 일어났다</p><pre><code class="bash">remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.</code></pre><p>–force 명령어에도 푸시가 안돼서 찾아보니, filter-branch를 통해 커밋 히스토리에서 삭제해야한다고.</p><pre><code class="bash">git filter-branch --tree-filter &#39;rm -f path/to/bigRdata/biggy.sav&#39; HEADgit push origin master --force</code></pre><p>필터 브랜치 명령어에서 삭제할 데이터의 path는 git bash에서 접근한 경로기준으로 (보통은 git의 루트디렉토리) 입력하면 된다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;회사에서 gitlab을 쓰면서 쾌적한 git life를 즐기다가 github에서는 100MB이상의 파일이 푸시가 안된다는 것을 알았다.&lt;br&gt;R 스터디 할때 써놓은 코드를 기록하려고 데이터와 함께 커밋을 해버렸는데, 커밋때 경고가 한번 떴(던거같
      
    
    </summary>
    
      <category term="Dev-Env" scheme="https://parkdoyeon.github.io/dev-env/"/>
    
    
      <category term="git" scheme="https://parkdoyeon.github.io/tags/git/"/>
    
      <category term="filter-branch" scheme="https://parkdoyeon.github.io/tags/filter-branch/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch - 도커를 이용해 인덱스 주기적으로 삭제하기</title>
    <link href="https://parkdoyeon.github.io/elk/elk-2019-04-02-es-curator/"/>
    <id>https://parkdoyeon.github.io/elk/elk-2019-04-02-es-curator/</id>
    <published>2019-04-02T08:35:00.000Z</published>
    <updated>2019-06-08T02:58:52.618Z</updated>
    
    <content type="html"><![CDATA[<p>로그를 끊임없이 ES에 저장하다보면 디스크 용량이 부족한 문제가 발생한다.<br>수동으로 인덱스를 삭제하다보면 단순히 번거로울 뿐만이 아니라 삭제하지 않으려고 했던 인덱스도 삭제될 수 있기 때문에, 삭제 자동화는 ES 운영에 반드시 필요하다.<br>curator는 elasticsearch의 인덱스를 관리를 위한 어플리케이션으로, ES와 격리된 환경에서 http 통신으로 동작이 가능하다.</p><p>여기에는 인덱스 삭제만 나와있지만, 샤드의 삭제나 엘라스틱서치의 스냅샷 삭제, 샤드 라우팅 변경도 가능하다.<br>나의 경우 curator를 세팅할 서버는 폐쇄된 환경이었기 때문에,<br>로컬에서 curator 공식사이트의 dockerfile을 받아 이미지를 빌드한 다음,<br>이미지를 파일로 압축해 서버에 세팅하고 cronjob을 통해 매일 인덱스 삭제작업을 진행하도록 했다.</p><h4 id="docker-image-빌드"><a href="#docker-image-빌드" class="headerlink" title="docker image 빌드"></a>docker image 빌드</h4><p>github에 올라와있는 dockerfile을 다운받아 빌드한다 <a href="https://github.com/elastic/curator" target="_blank" rel="noopener">https://github.com/elastic/curator</a></p><pre><code class="bash">docker build .</code></pre><h4 id="큐레이터-기본-설정파일-생성하기-curator-yml"><a href="#큐레이터-기본-설정파일-생성하기-curator-yml" class="headerlink" title="큐레이터 기본 설정파일 생성하기: curator.yml"></a>큐레이터 기본 설정파일 생성하기: curator.yml</h4><pre><code class="yml">client:  hosts:   - elasticsearch  port: 9200  url_prefix:  use_ssl: False  certificate:  client_cert:  client_key:  ssl_no_validate: False  http_auth:  timeout: 30  master_only: Falselogging:  loglevel: INFO  logfile: /volume/curator.log #로그 디렉토리 설정, 어플리케이션 수행   logformat: default  blacklist: [&#39;elasticsearch&#39;, &#39;urllib3&#39;]</code></pre><h4 id="인덱스-삭제-규칙파일-생성하기-delete-indices-yml"><a href="#인덱스-삭제-규칙파일-생성하기-delete-indices-yml" class="headerlink" title="인덱스 삭제 규칙파일 생성하기: delete-indices.yml"></a>인덱스 삭제 규칙파일 생성하기: delete-indices.yml</h4><pre><code class="yml">actions:  1:    action: delete_indices    options:      ignore_empty_list: True      disable_action: False    filters:     - filtertype: pattern       kind: prefix       value: kr-*-     - filtertype: age       source: name       direction: older       timestring: &#39;%Y.%m.%d&#39;       unit: days       unit_count: 8 #생성한지 8일이 된 데이터는 삭제한다</code></pre><h4 id="도커-컴포즈-설정"><a href="#도커-컴포즈-설정" class="headerlink" title="도커 컴포즈 설정"></a>도커 컴포즈 설정</h4><p>빌드된 이미지의 entrypoint는 아무 옵션 없이 단순히 어플리케이션을 실행하는 ‘curator/curator’이다.<br>때문에 설정파일이나 규칙들을 정의해주고싶다면 아래와 같이 entrypoint override를 해야한다.<br>또한, 어떤 인덱스가 삭제될지 확인하고싶다면 dry run 옵션을 통해 위의 curator.yml에 지정한 log파일에서 리스트확인이 가능하다.<br>최초 실행시 반드시 dry run을 통해 curator.log에 삭제 대상이 되는 인덱스들을 확인하자.</p><pre><code class="yml">version: &#39;3.3&#39;  services:    curator:      image: curator:5.6      container_name: curator      user: $USER      volumes:        - /data/volume/curator:/volume  # 테스트시 주석 해제 후 실행  #    entrypoint: [&quot;curator/curator&quot;, &quot;--config&quot;, &quot;/volume/config/curator.yml&quot;, &quot;--dry-run&quot;, &quot;/volume/config/delete-indices.yml&quot;]      entrypoint: [&quot;curator/curator&quot;, &quot;--config&quot;, &quot;/volume/config/curator.yml&quot;, &quot;/volume/config/delete-indices.yml&quot;]      network_mode: esmaster #엘라스틱 서치가 있는 네트워크와 맞춰주기</code></pre><h4 id="큐레이터로-도커컴포즈-실행하기"><a href="#큐레이터로-도커컴포즈-실행하기" class="headerlink" title="큐레이터로 도커컴포즈 실행하기"></a>큐레이터로 도커컴포즈 실행하기</h4><p>도커 컨테이너는 규칙 실행후 exit code 0을 반환하며 종료된다.<br>정기적으로 실행되도록 설정하려면 리눅스 cronjob 등록을 해줘야한다.</p><ol><li>도커 컴포즈 실행 스크립트 만들기<pre><code class="bash">#!/bin/bashcd /path/to/docker-composedocker-compose up</code></pre></li></ol><pre><code>2. 크론탭 에디터 열기``` bashcrontab -e</code></pre><ol start="3"><li>규칙 추가<br>매일 17시에 실행되고, cronjob 작업 수행 이력이 crontab.log에 남는다.<pre><code class="bash">0 17 * * * /data/volume/curator-run.sh &gt; /data/crontab.log 2&gt;&amp;1</code></pre></li></ol><p>완료후 반영은 wq를 통해 하면 된다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;로그를 끊임없이 ES에 저장하다보면 디스크 용량이 부족한 문제가 발생한다.&lt;br&gt;수동으로 인덱스를 삭제하다보면 단순히 번거로울 뿐만이 아니라 삭제하지 않으려고 했던 인덱스도 삭제될 수 있기 때문에, 삭제 자동화는 ES 운영에 반드시 필요하다.&lt;b
      
    
    </summary>
    
      <category term="ELK" scheme="https://parkdoyeon.github.io/elk/"/>
    
    
      <category term="elasticsearch" scheme="https://parkdoyeon.github.io/tags/elasticsearch/"/>
    
      <category term="docker" scheme="https://parkdoyeon.github.io/tags/docker/"/>
    
      <category term="curator" scheme="https://parkdoyeon.github.io/tags/curator/"/>
    
      <category term="index" scheme="https://parkdoyeon.github.io/tags/index/"/>
    
  </entry>
  
</feed>
