{"componentChunkName":"component---src-templates-post-js","path":"/deep-learning-from-scratch-1-퍼셉트론과-신경망","result":{"data":{"markdownRemark":{"html":"<h2 id=\"1-퍼셉트론\"><a href=\"#1-%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0\" aria-label=\"1 퍼셉트론 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 퍼셉트론</h2>\n<ul>\n<li>뉴런에서 보내온 신호 총합이 정해진 한계(임계값)를 넘어서면 1, 아니면 0을 출력하는게 기본 원리.</li>\n<li>\n<p>신호는 가중치값 \\(w\\)와 곱한다.</p>\n<ul>\n<li>전류에서 말하는 저항을 생각하면 된다.</li>\n<li>가중치가 높으면 신호가 크고, 가중치가 낮으면 신호가 낮다.</li>\n</ul>\n</li>\n<li>활성화를 조정하는 상수 편향값 \\(b\\)를 더한다.</li>\n<li>한계: AND, NAND(Not And: And의 반대 진리표), OR의 연산 구현이 가능하지만, XOR 게이트는 구현할 수 없다.</li>\n</ul>\n<h2 id=\"2-다층-퍼셉트론\"><a href=\"#2-%EB%8B%A4%EC%B8%B5-%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0\" aria-label=\"2 다층 퍼셉트론 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 다층 퍼셉트론</h2>\n<ul>\n<li>선형구조인 퍼셉트론의 대안으로, 다층적으로 구현하는 퍼셉트론을 말한다.</li>\n<li>다층 퍼셉트론의 NAND 연산만으로 컴퓨터를 구현할 수 있다.</li>\n</ul>\n<h2 id=\"3-신경망\"><a href=\"#3-%EC%8B%A0%EA%B2%BD%EB%A7%9D\" aria-label=\"3 신경망 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 신경망</h2>\n<ul>\n<li>입력층, 은닉층, 출력층으로 구성되어있다.</li>\n<li>두개의 신호 \\(w<em>1\\), \\(w</em>2\\)와 편향값 b가 있다고 가정할때, 다음과 같이 표현할 수 있다.\n$$ y= h(b+w<em>1x</em>1+w<em>2x</em>2) $$</li>\n<li>여기서 출력값 y를 도출하는 h(a)로 표현되는 함수는 활성화 함수라고 한다.</li>\n</ul>\n<h4 id=\"31-활성화-함수\"><a href=\"#31-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98\" aria-label=\"31 활성화 함수 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1 활성화 함수</h4>\n<ul>\n<li>활성화 함수는 신호의 총합을 출력의 신호로 변환하는 함수를 말한다.</li>\n<li>신경망은 활성화 함수를 통해 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다.</li>\n<li>\n<p>책에서는 활성화 함수로 세 가지를 소개한다.</p>\n<ol>\n<li>\n<p>계단함수</p>\n<ul>\n<li>입력이 0을 넘으면 1을, 그 외에는 0을 출력하는 함수이다.</li>\n</ul>\n</li>\n<li>\n<p>시그모이드 함수</p>\n<ul>\n<li>시그모이드 함수는 아래의 공식을 나타내며, e는 자연상수이다.\n$$ h(x)= {1 \\over 1+exp(-x)}$$\n$$  exp(-x) = e^{-x}, e=2.7182... $$</li>\n</ul>\n</li>\n<li>\n<p>ReLU 함수</p>\n<ul>\n<li>입력이 0을 넘으면 그 입력을 그대로 출력하고, 0이하면 0을 출력하는 함수이다.</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>\n<p>세 함수는 공통적으로 비선형 함수이고, 신경망에서는 활성화 함수로 비선형 함수를 사용해야한다</p>\n<ul>\n<li>선형함수를 이용하면 미분값이 값이 상수가 되며, 변화량이 상수면 신경망 층을 깊게하는 의미가 없어지기 때문이다.</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"32-출력층-설계하기\"><a href=\"#32-%EC%B6%9C%EB%A0%A5%EC%B8%B5-%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0\" aria-label=\"32 출력층 설계하기 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.2 출력층 설계하기</h4>\n<ul>\n<li>기계학습은 분석(classification, 입력데이터를 구분), 회귀(regression, 입력데이터에서 연속적인 수치 예측)따라 활성화 함수를 달리쓴다.</li>\n<li>\n<p>두가지를 소개한다.</p>\n<ol>\n<li>항등함수</li>\n<li>회귀에서 주로 사용한다. 입력을 그대로 출력함.</li>\n<li>소프트맥스</li>\n<li>분류에서 주로 사용한다.</li>\n<li>\n<p>분자는 입력신호의 지수함수, 분모는 n개의 모든 입력신호의 지수함수의 합으로 구성된다\n$$  y<em>k = {exp(a</em>k) \\over \\sum_ {i=0}^n exp(a_i)} $$</p>\n<ul>\n<li>분모의 값을 보면 모든 출력층의 뉴런이 모든 신호로부터 영향을 받는 것을 알 수 있다.</li>\n<li>소프트 맥스 함수는 코드 구현시 지수값으로 인한 오버플로 문제가 있다. 이를 개선하기 위해 입력신호중 최대값을 뺀다.</li>\n<li>아래의 식을 보면 어떤값을 더하거나 뺴도 결과값은 동일하다는 것을 보여준다.\n$$  y<em>k = {exp(a</em>k) \\over \\sum_ {i=0}^n exp(a<em>i)} = {Cexp(a</em>k) \\over C\\sum_ {i=0}^n exp(a<em>i)}  $$\n\\(exp(n)\\)는 지수함수이므로 C를 지수식에 밑이 e인 자연로그($log</em>e$)으로 취하면 덧셈식에 넣을 수 있다.\n$$  = {exp(a<em>k+logC) \\over \\sum</em> {i=0}^n exp(a<em>i+logC)} = {exp(a</em>k+C') \\over \\sum_ {i=0}^n exp(a_i+C')}$$</li>\n</ul>\n</li>\n<li>소프트 맥스 함수의 출력은 0부터 1사이의 실수이며, 그렇기 때문에 출력을 확률로 해석할 수 있다.</li>\n<li>\\(y=exp(x)\\)형식의 단조 증가함수이므로 원소간의 대소관계가 바뀌지는 않는다.</li>\n<li>그렇기 떄문에 지수함수 계산에 드는 자원 낭비를 줄이기 위해 현업에서는 출력층의 소프트맥스 함수를 생략하기도 한다.</li>\n</ol>\n</li>\n</ul>","timeToRead":3,"excerpt":"1. 퍼셉트론 뉴런에서 보내온 신호 총합이 정해진 한계(임계값)를 넘어서면 1, 아니면 0을 출력하는게 기본 원리. 신호는 가중치값 \\(w…","frontmatter":{"title":"Deep Learning From Scratch - 1. 퍼셉트론과 신경망","cover":"","date":"2019-05-27T19:38:00.000Z","categories":["ML"],"tags":["machine-learning","deep-learning"]},"fields":{"slug":"/deep-learning-from-scratch-1-퍼셉트론과-신경망","date":"May 26, 2019"}}},"pageContext":{"slug":"/deep-learning-from-scratch-1-퍼셉트론과-신경망","nexttitle":"Hyper-V - 네트워크 환경세팅하기","nextslug":"/hyper-v-네트워크-환경세팅하기","prevtitle":"ssms 사용할때 자주쓰는 명령어 정리","prevslug":"/ssms-사용할때-자주쓰는-명령어-정리"}}}