<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta name="google-site-verification" content="ZPpg1XKRwaiB4lPx6SawBAA96ROVlVBmZ8s6pigFEVc">



<meta name="naver-site-verification" content="a31e494cb7e78d5a64696ea234dc6c9006b251ff">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">


<meta property="og:type" content="website">
<meta property="og:url" content="https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/">


  <meta property="og:title" content="Deep Learning From Scratch - 2. 신경망 학습">




  <meta name="description" content="Deep Learning From Scratch - 2. 신경망 학습">
  <meta property="og:description" content="Deep Learning From Scratch - 2. 신경망 학습">





  <meta name="keywords" content="machine-learning,deep-learning,">





  <link rel="alternate" href="/atom.xml" title="Park Doyeon">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=">



<link rel="canonical" href="https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/">


<meta name="description" content="개요 ‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻한다. 매개변수 최적값을 학습할 수 있도록 해주는 지표는 손실함수이다. 왜 정확도가 아닌 손실함수인가? 정확도를 지표료 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. (= 소숫점 단위로 표현되는 연속적인 수치값이 아닌 단절된 숫자값으로 표현되기가 쉽다.)">
<meta name="keywords" content="machine-learning,deep-learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning From Scratch - 2. 신경망 학습">
<meta property="og:url" content="https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/index.html">
<meta property="og:site_name" content="Park Doyeon">
<meta property="og:description" content="개요 ‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻한다. 매개변수 최적값을 학습할 수 있도록 해주는 지표는 손실함수이다. 왜 정확도가 아닌 손실함수인가? 정확도를 지표료 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. (= 소숫점 단위로 표현되는 연속적인 수치값이 아닌 단절된 숫자값으로 표현되기가 쉽다.)">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://parkdoyeon.github.io/image/ml/2019-06-02-deep2-1.png">
<meta property="og:updated_time" content="2019-06-27T15:33:15.455Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Learning From Scratch - 2. 신경망 학습">
<meta name="twitter:description" content="개요 ‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻한다. 매개변수 최적값을 학습할 수 있도록 해주는 지표는 손실함수이다. 왜 정확도가 아닌 손실함수인가? 정확도를 지표료 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. (= 소숫점 단위로 표현되는 연속적인 수치값이 아닌 단절된 숫자값으로 표현되기가 쉽다.)">
<meta name="twitter:image" content="https://parkdoyeon.github.io/image/ml/2019-06-02-deep2-1.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141653278-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-141653278-1');
  </script>





  


    <title> Deep Learning From Scratch - 2. 신경망 학습 - Park Doyeon </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Park Doyeon</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>
      </header>

      <div id="post-categories"><ul class="category-list">

    <li>
    
        <a href="/docker">Docker</a>
    
    </li>

    <li>
    
        <a href="/dev-env">Dev-Env</a>
    
    </li>

    <li>
    
        <a href="/ml" class="on">ML</a>
    
    </li>

    <li>
    
        <a href="/csharp">C#</a>
    
    </li>

    <li>
    
        <a href="/python">Python</a>
    
    </li>

    <li>
    
        <a href="/undefined">python</a>
    
    </li>

    <li>
    
        <a href="/sql">SQL</a>
    
    </li>

    <li>
    
        <a href="/web">Web</a>
    
    </li>

    <li>
    
        <a href="/elk">ELK</a>
    
    </li>

</ul>

      </div>

      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Deep Learning From Scratch - 2. 신경망 학습
        
      </h1>

      <time class="post-time">
          Jun 2 2019
      </time>
    </header>



    
            <div class="post-content">
            <h3 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h3><ul>
<li>‘학습’이란 훈련 데이터로부터 가중치 매개변수의 최적값을 <strong>자동</strong>으로 획득하는 것을 뜻한다.</li>
<li>매개변수 최적값을 학습할 수 있도록 해주는 <strong>지표</strong>는 손실함수이다.<ul>
<li>왜 정확도가 아닌 손실함수인가?<ul>
<li>정확도를 지표료 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. (= 소숫점 단위로 표현되는 연속적인 수치값이 아닌 단절된 숫자값으로 표현되기가 쉽다.)</li>
</ul>
</li>
</ul>
</li>
<li>손실함수를 최대한 작게 만들어주도록 하는 기법중 하나로, 함수의 기울기를 활용하는 것이 ‘경사법’이다.</li>
<li>입력부터 출력까지 사람의 개입이 없다는 의미에서, 딥러닝을 종단간 기계학습(end-to-end learning)이라고 한다.</li>
<li>한 데이터셋에만 지나치게 최적화된 상태를 <strong>오버피팅</strong>이라고 한다.</li>
</ul>
<h3 id="1-손실함수"><a href="#1-손실함수" class="headerlink" title="1. 손실함수"></a>1. 손실함수</h3><h4 id="1-1-평균-제곱-오차"><a href="#1-1-평균-제곱-오차" class="headerlink" title="1.1 평균 제곱 오차"></a>1.1 평균 제곱 오차</h4><p>$$ E = { { 1\over2 } \sum_ { k } ( y_k-t_k)^2 } $$</p>
<ul>
<li>\(y_k\)는 신경망이 추정한 출력값, \(t_k\)는 실제 정답레이블 값(원-핫 인코딩), k는 차원의 수를 의미한다.</li>
<li>결과값으로 나타난 손실값의 합들이 높을수록 정답과 멀어지고, 적을수록 정답에 가깝다.</li>
</ul>
<h4 id="1-2-교차-엔트로피-오차"><a href="#1-2-교차-엔트로피-오차" class="headerlink" title="1.2 교차 엔트로피 오차"></a>1.2 교차 엔트로피 오차</h4><p>$$  E = - { \sum_ { k } t_k logy_k } $$</p>
<ul>
<li>여기서 \(logy\)는 자연로그 \(log_en\)를 취한다.</li>
<li>\(t_k\)는 원-핫 인코딩 값이므로 실질적으로 \(t_k\)가 1일때의 \(logy_k\)을 계산한 값, 즉 정답 추정값의 자연로그를 계산하는 식이 된다.<ul>
<li>여기서 정답과 거리가 먼 결과가 발생할수록(x가 1에 가까워질수록) 엔트로피 오차(loss)가 더 크게 발생한다.</li>
<li>\(log_ex=y\)의 그래프<br><img src="/image/ml/2019-06-02-deep2-1.png" alt="log_ex=y의 그래프"></li>
<li>가령 신경망 출력이 0.6일때 교차 엔트로피 오차가 \(-log0.6 = 0.51\)이라면, 0.1일때는 \(-log0.1=2.3\)이 된다.</li>
</ul>
</li>
</ul>
<h4 id="1-3-미니-배치-함수"><a href="#1-3-미니-배치-함수" class="headerlink" title="1.3 미니 배치 함수"></a>1.3 미니 배치 함수</h4><p>$$  E = - { 1 \over N } \sum { \sum_ { k } t_k logy_k } $$</p>
<ul>
<li>앞서서 구한 교차 엔트로피 오차를 모두 구해서 갯수만큼 나누면 평균 교차 엔트로피값을 구할 수 있다. 이렇게 하면 훈련 데이터 개수와 관계없이 통일된 지표를 구할 수 있다.</li>
<li>전체 데이터가 수천 수십만개가 되면 교차 엔트로피 값을 구하는것은 무리가 있으므로 데이터 일부를 추려서 근사치로 이용할 수 있다.</li>
<li>추려진 일부 데이터를 <strong>미니배치</strong>라고 한다.</li>
</ul>
<h3 id="2-수치미분"><a href="#2-수치미분" class="headerlink" title="2. 수치미분"></a>2. 수치미분</h3><h4 id="2-1-수치미분과-오차"><a href="#2-1-수치미분과-오차" class="headerlink" title="2.1 수치미분과 오차"></a>2.1 수치미분과 오차</h4><ul>
<li>미분방법에는 수치 미분과 해석적 미분이 있다.<ol>
<li>수치미분은 실제 변화량을 수치적으로 계산하는 것으로, 변화값인 h에 최대한 작은 값(보통 \(\lim_{h\to0}\)으로 표현된다.)을 대입하여 계산한다.</li>
<li>해석적 미분은 수식적으로 미분함수를 만들어 미분값을 찾는 것을 의미한다.</li>
</ol>
</li>
<li>수치미분을 코드로직에 적용할 때 h의 최솟값을 대입하다보면 아래와 같은 문제가 발생한다.<br>수치미분을 구하는 파이썬 함수를 예로들면,<pre><code class="python">  def numerical_diff(f, x):
      h = 10e-50
      return (f(x+h)+f(x)/h)</code></pre>
  아래와 같이 소숫점 8자리 이하부터 생략해 최종 계산값에 오차가 발생한다.<pre><code class="bash">  &gt;&gt;&gt; np.float32(1e-50)
  0.0</code></pre>
  때문에 \(10^{-4}\)정도의 값을 사용할 것을 권장한다.</li>
<li>수치미분에서 발생하는 오차는 필연적이기 때문에, 변화량이 +h인 미분과 -h인 미분의 중앙값을 구하기도 한다.</li>
</ul>
<h4 id="2-2-편미분"><a href="#2-2-편미분" class="headerlink" title="2.2 편미분"></a>2.2 편미분</h4><ul>
<li>편미분은 변수가 2개 이상인 경우에 사용한다. 3차원으로 그래프가 그려지므로, 미분값을 구할때는 변수 하나에 초점을 맞추고 다른 변수는 값을 고정한다.</li>
<li>편미분한 기울기 값에 마이너스 부호를 붙이고 2차원 벡터로 표현하면 각 지점에서 낮아지는 방향을 가리킨다. </li>
<li>이말인 즉, <strong>기울기가 가리키는 곳은 각 장소의 함수에서 함수의 출력 값을 가장 크게 줄이는 방향</strong>이다.</li>
</ul>
<h4 id="2-3-경사법"><a href="#2-3-경사법" class="headerlink" title="2.3 경사법"></a>2.3 경사법</h4><ul>
<li>경사법은 경사 하강법이라고 한다. 손실함수가 최소가 되는 값을 찾기위해 기울기를 활용하는 방법이다.</li>
<li>기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지는 보장할 수 없다. 실제로 최솟값이 없는 경우가 대부분이다.</li>
<li>다만 그 방향으로 가야 줄일 수 있다는 사실은 확실하므로, 기울어진 방향으로 일정 거리만큼 이동해나가면서 줄이는게 경사법이라고 한다.</li>
<li>최솟값을 찾으면 경사 하강법, 최댓값을 찾으면 경사 상승법이다. 단순히 기울기에 마이너스를 붙이냐 아니냐의 차이이므로 방법과 내용의 실질적인 차이는 없다.</li>
</ul>
<h3 id="2-3-1-경사법의-수식"><a href="#2-3-1-경사법의-수식" class="headerlink" title="2.3.1 경사법의 수식"></a>2.3.1 경사법의 수식</h3><p>$$ x_0 = x_0 - \eta { \partial f \over \partial x_0 },  x_1 = x_1 - \eta { \partial f \over \partial x_1 } $$</p>
<ul>
<li><p>\( \eta \)(eta)기호는 갱신하는 양을 나타낸다. 보통 0.01이나 0.001 등 특정값으로 정해둔다. 신경망 학습에서는 <strong>학습률</strong>이라고 한다.</p>
</li>
<li><p>위의 식은 1회의 갱신이 일어나는 식이며, 만족스러운 값이 나타날때까지 갱신을 반복한다.</p>
<pre><code class="python">  # f: 최적화 함수
  # init_x: 초기값
  # learning_rate: 학습률
  # step_num: 경사법에 따른 반복횟수 
  def gradient_descent (f, init_x, learning_rate=0.01, step_num=100):
      x=init_x

      for i in range(step_num):
          grad = numerical_gradient(f, x)
          x -= lr*grad
      return x</code></pre>
</li>
<li><p>학습률과 같은 매개변수를 하이퍼파라미터라고 한다. 가중치/편향과 같은 신경망 매개변수와는 성질이 다른 매개변수이다.</p>
</li>
</ul>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/machine-learning/">machine-learning</a>
          
            <a href="/tags/deep-learning/">deep-learning</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/web/web-2019-06-07-mathjax/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">hexo에 mathjax 적용하기</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/elk/elk-2019-05-31-es-shards/">
        <span class="next-text nav-default">ElasticSearch - unassigned shard 문제 해결 (1) shard가 너무 많을 때</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
    <!--<div style="text-align:center;">
        <button class="btn" id="load-disqus" onclick="disqus.load();">load Disqus review</button>
    </div>-->
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
    2019
    <span class="footer-author">Park Doyeon.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/" rel="external nofollow noopener noreferrer" target="_blank">Hexo</a> and <a class="theme-link" href="https://github.com/parkdoyeon">Me</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    

<script type="text/javascript">
  var disqus_shortname = 'parkdoyeon';
  var disqus_identifier = 'ml/ml-2019-06-02-deep2/';
  var disqus_url = 'https://parkdoyeon.github.io/ml/ml-2019-06-02-deep2/index.html';

  
  var disqus_config = function () {
      this.page.url = disqus_url;
      this.page.identifier = disqus_identifier;
  };
  
  (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  
  
  // var disqus = {
  //   load : function disqus(){
  //       if(typeof DISQUS !== 'object') {
  //         (function () {
  //         var s = document.createElement('script'); s.async = true;
  //         s.type = 'text/javascript';
  //         s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  //         (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
  //         }());
  //         $('#load-disqus').remove(); ///Delete Button
  //       }
  //   }
  // }

</script>


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script src="/js/src/theme.js?v="></script>
<script src="/js/src/bootstrap.js?v="></script>


    <script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<script src="/js/src/highlight.pack.js?v="></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.7.0/highlightjs-line-numbers.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
  document.querySelectorAll('figure.highlight').forEach((block) => {
    hljs.highlightBlock(block);
  });
});
hljs.initHighlightingOnLoad();
hljs.initLineNumbersOnLoad();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </body>
</html>
